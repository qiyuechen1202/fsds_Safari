{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1efb9da3-ff66-48c4-9760-b55425017d70",
   "metadata": {},
   "source": [
    "# FSDS Group Assessment (Group Safari)\n",
    "\n",
    "## 1. Data Collection and Cleaning\n",
    "We will use 2 different datasets:\n",
    "1. Airbnb data of London (10 Dec, 2022) downloading from [InsideAirbnb](http://insideairbnb.com/get-the-data)  \n",
    "2. 2011 and 2021 Census data including:\n",
    "* popchurn 11.csv\n",
    "* MIG009EW_LTLA_OUT.csv\n",
    "* MIG009EW_LTLA_IN.csv\n",
    "* ethnic group 2011.csv\n",
    "* ethnic group 2021.csv\n",
    "* house price_median.xls\n",
    "* house price_aver.xlsx\n",
    "* Deprivation 2011.xls\n",
    "* Deprivation 2021.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900b1c81-c4e8-44ec-bd43-9ecb7886b2bc",
   "metadata": {},
   "source": [
    "### 1.1 Input data and create dataframe\n",
    "\n",
    "Note that all data in the Data subdirectory is ignored in the `.gitignore` file. <span style=\"color:red\">(***We may need to change the setting of our repo later.***)</span>\n",
    "\n",
    "The file names that are used in this script are as follows.\n",
    "\n",
    "|Data Type|File Name|df/gdf name|Gentrification Score Column Name|\n",
    "|:---|:---|:---|:--|\n",
    "||`popchurn 11.csv`|`popch2011`|`2011moving%`|\n",
    "||`MIG009EW_LTLA_OUT.csv`|`moving2021`|`2021moving%`|\n",
    "||`MIG009EW_LTLA_IN.csv`|||\n",
    "||`ethnic group 2011.csv`|`eg2011`|`w_ratio11`|\n",
    "||`ethnic group 2021.csv`|`eg2021`|`w_ratio21`|\n",
    "||`house price_median.xls`|`price_med`|`houseprice%`|\n",
    "||`house price_aver.xlsx`|`housing_df`||\n",
    "||`Deprivation 2011.xls`|`dpr2011`|`dpr2011%`|\n",
    "||`Deprivation 2021.csv`|`dpr2021`|`dpr2021%`|\n",
    "|`Airbnb point`|`borough`|||\n",
    "|`Airbnb polygon`||||\n",
    "|`Airbnb point`||||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821697a0-b2bf-46a6-b94e-5ff111171ffa",
   "metadata": {},
   "source": [
    "#### 1.1.1 Get Prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d77d5c-c664-4d78-a926-4b4d32dc68c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<jemalloc>: MADV_DONTNEED does not work (memset will be used instead)\n",
      "<jemalloc>: (This is the expected behaviour if you are running under QEMU)\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "from requests import get\n",
    "from urllib.parse import urlparse\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbef2c0-2843-4212-b6be-3692565aa8b9",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">For now, I am using local files, so the next coding cell won't be helpful. But I'll adjust it later to download directly using url.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3951fa7b-2975-4e9f-8df7-6170dfc70b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from remote location\n",
    "def cache_data(src:str, dest:str) -> str:\n",
    "    \"\"\"Downloads and caches a remote file locally.\n",
    "    \n",
    "    The function sits between the 'read' step of a pandas or geopandas\n",
    "    data frame and downloading the file from a remote location. The idea\n",
    "    is that it will save it locally so that you don't need to remember to\n",
    "    do so yourself. Subsequent re-reads of the file will return instantly\n",
    "    rather than downloading the entire file for a second or n-th itme.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    src : str\n",
    "        The remote *source* for the file, any valid URL should work.\n",
    "    dest : str\n",
    "        The *destination* location to save the downloaded file.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A string representing the local location of the file.\n",
    "    \"\"\"\n",
    "    url = urlparse(src)\n",
    "    fn  = os.path.split(url.path)[-1]\n",
    "    dfn = os.path.join(dest,fn)\n",
    "    \n",
    "    if not os.path.isfile(dfn):\n",
    "        print(f\"{dfn} not found, downloading!\")\n",
    "        path = os.path.split(dest)\n",
    "        \n",
    "        if len(path) >= 1 and path[0] != '':\n",
    "            os.makedirs(os.path.join(*path), exist_ok=True)\n",
    "            \n",
    "        with open(dfn, \"wb\") as file:\n",
    "            response = get(src)\n",
    "            file.write(response.content)  \n",
    "        print(\"\\tDone downloading...\")\n",
    "    else:\n",
    "        print(f\"Found {dfn} locally!\")\n",
    "        \n",
    "    return dfn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed83e647-0164-42e2-a536-44db194e955e",
   "metadata": {},
   "source": [
    "Please save data files under directory: ***Data/*** which is in the same level as this ipynb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9336107a-6380-4e54-8fbf-7a6a1bd8a712",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/jovyan/work/Documents/casa/fsds/group')\n",
    "padir = 'Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e02b44-85ed-4063-92d6-0bef107c259f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1.1.2 Read Files and Select Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2415063f-5b91-40f9-a779-43802758efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Population Churn\n",
    "popch2011 = pd.read_csv(padir+'popchurn 11.csv', skiprows=7, skip_blank_lines=True, usecols=[\n",
    "    'local authority: district / unitary (prior to April 2015)',\n",
    "    'mnemonic',\n",
    "    'Whole household lived at same address one year ago', \n",
    "    'Wholly moving household: Total']).dropna(how='all').iloc[:33]\n",
    "\n",
    "popch2021_in_raw = pd.read_csv(padir + 'MIG009EW_LTLA_IN.csv', usecols=['Lower tier local authorities code', 'Household migration LTLA (inflow) (7 categories) code', 'Count'])\n",
    "popch2021_out_raw = pd.read_csv(padir + 'MIG009EW_LTLA_OUT.csv', usecols=['Migrant LTLA one year ago code', 'Household migration LTLA (outflow) (3 categories) code', 'Count'])\n",
    "\n",
    "popch2021_in = popch2021_in_raw.loc[popch2021_in_raw['Lower tier local authorities code'].astype(str).str.match(r'^E090000[0-9]{2}$|^E09000[1-3][0-3]$', na=False)]\n",
    "popch2021_out = popch2021_out_raw.loc[popch2021_out_raw['Migrant LTLA one year ago code'].astype(str).str.match(r'^E090000[0-9]{2}$|^E09000[1-3][0-3]$', na=False)]\n",
    "\n",
    "## Ethnic Group\n",
    "eg2011 = pd.read_csv(padir+'ethnic group 2011.csv', skiprows=7, header=0, skip_blank_lines=True, usecols=[\n",
    "    'mnemonic','All categories: Ethnic group','White'])\n",
    "eg2021 = pd.read_csv(padir+'ethnic group 2021.csv', skiprows=6, header=0, skip_blank_lines=True, usecols=[\n",
    "    'mnemonic','Total: All usual residents','White'])\n",
    "\n",
    "## Housing price\n",
    "# median housing price\n",
    "price_med_raw = pd.read_excel(padir+'house price_median.xls',sheet_name='1a',engine='xlrd',skiprows=5,header=0,usecols=[\n",
    "    'Local authority code','Year ending Dec 2001','Year ending Dec 2021'])\n",
    "price_med = price_med_raw.loc[price_med_raw['Local authority code'].astype(str).str.contains(r'^E09', regex=True)]\n",
    "price_med.set_index('Local authority code', inplace=True)\n",
    "# average housing price \n",
    "housing_price = \"house price_aver.xlsx\"\n",
    "housing_df = pd.read_excel(os.path.join(padir, housing_price),sheet_name=2,skiprows=1, header=0,index_col=0)\n",
    "\n",
    "## Deprivation\n",
    "dpr2011_raw = pd.read_excel(padir+'deprivation 2011.xls',sheet_name='QS119EW_Percentages',engine='xlrd',skiprows=10,header=0, usecols=[\n",
    "    'Area code','Household is not deprived in any dimension'])\n",
    "dpr2011 = dpr2011_raw.loc[dpr2011_raw['Area code'].astype(str).str.contains(r'^E090000[0-2][0-9]$|^E090003[0-3]$|^E090000[1-9][0-9]$|^E09000[1-3][0-3]$'\n",
    ", regex=True)]\n",
    "\n",
    "dpr2021_raw = pd.read_csv(padir+'deprivation 2021.csv')\n",
    "dpr2021 = dpr2021_raw[dpr2021_raw['Upper tier local authorities Code'].astype(str).str.contains(\n",
    "    r'^E090000[0-2][0-9]$|^E090003[0-3]$|^E090000[1-9][0-9]$|^E09000[1-3][0-3]$', regex=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2cdf89-e0b7-4015-b883-c9a0c383cdc5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.2 Calculate Gentrification Score\n",
    "G = 1/2c - 1/4e + 1/8h - 1/8d + 0.25  \n",
    "    c: population churn at household level - the ratio of the households that have changed  \n",
    "    e: ethnic group - the change of the proportion of non-white residents  \n",
    "    h: housing price - relative change in median house price compared with acerage price  \n",
    "    d: deprivation - relative change in the proportion of households with deprivation dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79998c96-c5b5-471d-b818-8646baa48486",
   "metadata": {},
   "source": [
    "#### 1.2.1   c: Population Churn (Household Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "400146d2-1e09-4dfd-9e0b-7094d605a303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   borough borough code  2011moving%\n",
      "1     Barking and Dagenham    E09000002    11.314102\n",
      "2                   Barnet    E09000003    13.528176\n",
      "3                   Bexley    E09000004     8.559739\n",
      "4                    Brent    E09000005    14.025929\n",
      "5                  Bromley    E09000006    10.936476\n",
      "6                   Camden    E09000007    19.379820\n",
      "7           City of London    E09000001    27.085688\n",
      "8                  Croydon    E09000008    11.519518\n",
      "9                   Ealing    E09000009    13.772567\n",
      "10                 Enfield    E09000010    12.009192\n",
      "11               Greenwich    E09000011    14.079714\n",
      "12                 Hackney    E09000012    15.340250\n",
      "13  Hammersmith and Fulham    E09000013    19.660653\n",
      "14                Haringey    E09000014    16.727549\n",
      "15                  Harrow    E09000015    11.357007\n",
      "16                Havering    E09000016     8.166717\n",
      "17              Hillingdon    E09000017    11.185262\n",
      "18                Hounslow    E09000018    14.295874\n",
      "19               Islington    E09000019    18.308749\n",
      "20  Kensington and Chelsea    E09000020    21.433206\n",
      "21    Kingston upon Thames    E09000021    14.384456\n",
      "22                 Lambeth    E09000022    17.242787\n",
      "23                Lewisham    E09000023    14.290862\n",
      "24                  Merton    E09000024    14.170024\n",
      "25                  Newham    E09000025    14.389341\n",
      "26               Redbridge    E09000026    12.374547\n",
      "27    Richmond upon Thames    E09000027    15.877061\n",
      "28               Southwark    E09000028    16.172823\n",
      "29                  Sutton    E09000029    10.113656\n",
      "30           Tower Hamlets    E09000030    20.403332\n",
      "31          Waltham Forest    E09000031    13.050069\n",
      "32              Wandsworth    E09000032    18.560413\n",
      "33             Westminster    E09000033    22.667469\n"
     ]
    }
   ],
   "source": [
    "gtr = pd.DataFrame()\n",
    "## 2011 moving households\n",
    "popch2011['2011moving%'] = (100*\n",
    "    (popch2011['Wholly moving household: Total'] /\n",
    "    (popch2011['Wholly moving household: Total'] + popch2011['Whole household lived at same address one year ago'])))\n",
    "\n",
    "gtr['borough'] = popch2011['local authority: district / unitary (prior to April 2015)']\n",
    "gtr['borough code'] = popch2011['mnemonic']\n",
    "gtr['2011moving%'] = popch2011['2011moving%']\n",
    "print(gtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fbf04250-b51b-433a-aa76-dbc93118d7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   borough borough code  2011moving%  2021moving%  popchurn%\n",
      "0     Barking and Dagenham    E09000002    11.314102    11.096466  -0.217636\n",
      "1                   Barnet    E09000003    13.528176    13.449671  -0.078505\n",
      "2                   Bexley    E09000004     8.559739     9.228325   0.668586\n",
      "3                    Brent    E09000005    14.025929    15.189397   1.163468\n",
      "4                  Bromley    E09000006    10.936476    10.685033  -0.251443\n",
      "5                   Camden    E09000007    19.379820    21.068651   1.688831\n",
      "6           City of London    E09000001    27.085688    32.213164   5.127475\n",
      "7                  Croydon    E09000008    11.519518    11.934819   0.415301\n",
      "8                   Ealing    E09000009    13.772567    14.096957   0.324390\n",
      "9                  Enfield    E09000010    12.009192    10.912710  -1.096482\n",
      "10               Greenwich    E09000011    14.079714    13.880816  -0.198898\n",
      "11                 Hackney    E09000012    15.340250    17.696536   2.356286\n",
      "12  Hammersmith and Fulham    E09000013    19.660653    21.308668   1.648015\n",
      "13                Haringey    E09000014    16.727549    15.956565  -0.770984\n",
      "14                  Harrow    E09000015    11.357007    12.182632   0.825626\n",
      "15                Havering    E09000016     8.166717     9.618064   1.451346\n",
      "16              Hillingdon    E09000017    11.185262    11.658885   0.473623\n",
      "17                Hounslow    E09000018    14.295874    13.560026  -0.735848\n",
      "18               Islington    E09000019    18.308749    20.568013   2.259264\n",
      "19  Kensington and Chelsea    E09000020    21.433206    21.731359   0.298153\n",
      "20    Kingston upon Thames    E09000021    14.384456    13.944801  -0.439655\n",
      "21                 Lambeth    E09000022    17.242787    18.535245   1.292458\n",
      "22                Lewisham    E09000023    14.290862    14.331798   0.040935\n",
      "23                  Merton    E09000024    14.170024    14.593653   0.423629\n",
      "24                  Newham    E09000025    14.389341    16.223485   1.834143\n",
      "25               Redbridge    E09000026    12.374547    12.375257   0.000710\n",
      "26    Richmond upon Thames    E09000027    15.877061    14.257492  -1.619569\n",
      "27               Southwark    E09000028    16.172823    17.516394   1.343571\n",
      "28                  Sutton    E09000029    10.113656    10.656790   0.543134\n",
      "29           Tower Hamlets    E09000030    20.403332    22.956356   2.553024\n",
      "30          Waltham Forest    E09000031    13.050069    13.489598   0.439528\n",
      "31              Wandsworth    E09000032    18.560413    20.299919   1.739505\n",
      "32             Westminster    E09000033    22.667469    23.928932   1.261464\n"
     ]
    }
   ],
   "source": [
    "# 2022 moving households\n",
    "# population churn = moving household / all household =  moving household / (not moving household +  moving household)\n",
    "samead = popch2021_in.loc[popch2021_in['Household migration LTLA (inflow) (7 categories) code'] == 1].groupby('Lower tier local authorities code')['Count'].sum().reset_index()\n",
    "movein = popch2021_in.loc[(popch2021_in['Household migration LTLA (inflow) (7 categories) code'] >= 2) & (popch2021_in['Household migration LTLA (inflow) (7 categories) code'] <= 5)].groupby('Lower tier local authorities code')['Count'].sum().reset_index()\n",
    "moveout = popch2021_out.loc[(popch2021_out['Household migration LTLA (outflow) (3 categories) code'] >= 1) & (popch2021_out['Household migration LTLA (outflow) (3 categories) code'] <= 2)].groupby('Migrant LTLA one year ago code')['Count'].sum().reset_index()\n",
    "\n",
    "samead = samead.rename(columns={'Lower tier local authorities code': 'code'})\n",
    "movein = movein.rename(columns={'Lower tier local authorities code': 'code'})\n",
    "moveout = moveout.rename(columns={'Migrant LTLA one year ago code': 'code'})\n",
    "\n",
    "moving2021 = (\n",
    "    (movein.set_index('code')['Count'] +moveout.set_index('code')['Count']) /\n",
    "    (samead.set_index('code')['Count'] + movein.set_index('code')['Count'] + moveout.set_index('code')['Count'])\n",
    ").reset_index(name='2021moving%') * 100\n",
    "\n",
    "# Extract the first part of 'code' in moving2021\n",
    "moving2021['code'] = moving2021['code'].str.slice(0, 9)\n",
    "\n",
    "# Merge the result into gtr based on 'borough code' and 'code'\n",
    "gtr = gtr.merge(moving2021, how='left', left_on='borough code', right_on='code',suffixes=('', '_y'))\n",
    "\n",
    "# Drop the redundant 'code' column\n",
    "gtr = gtr.drop(columns=['code'])\n",
    "\n",
    "# add 'popchurn' column: \n",
    "gtr['popchurn%'] = gtr['2021moving%'] - gtr['2011moving%']\n",
    "# Display the resulting DataFrame gtr\n",
    "print(gtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19ee372-38ba-498d-8bb4-85964a7d5190",
   "metadata": {},
   "source": [
    "#### 1.2.2 e: Non-white Ethnic Group Proportion Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "62439c8e-cb74-4cf9-a4e9-6728c2746533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   borough borough code  2011moving%  2021moving%  popchurn%  \\\n",
      "0     Barking and Dagenham    E09000002    11.314102    11.096466  -0.217636   \n",
      "1                   Barnet    E09000003    13.528176    13.449671  -0.078505   \n",
      "2                   Bexley    E09000004     8.559739     9.228325   0.668586   \n",
      "3                    Brent    E09000005    14.025929    15.189397   1.163468   \n",
      "4                  Bromley    E09000006    10.936476    10.685033  -0.251443   \n",
      "5                   Camden    E09000007    19.379820    21.068651   1.688831   \n",
      "6           City of London    E09000001    27.085688    32.213164   5.127475   \n",
      "7                  Croydon    E09000008    11.519518    11.934819   0.415301   \n",
      "8                   Ealing    E09000009    13.772567    14.096957   0.324390   \n",
      "9                  Enfield    E09000010    12.009192    10.912710  -1.096482   \n",
      "10               Greenwich    E09000011    14.079714    13.880816  -0.198898   \n",
      "11                 Hackney    E09000012    15.340250    17.696536   2.356286   \n",
      "12  Hammersmith and Fulham    E09000013    19.660653    21.308668   1.648015   \n",
      "13                Haringey    E09000014    16.727549    15.956565  -0.770984   \n",
      "14                  Harrow    E09000015    11.357007    12.182632   0.825626   \n",
      "15                Havering    E09000016     8.166717     9.618064   1.451346   \n",
      "16              Hillingdon    E09000017    11.185262    11.658885   0.473623   \n",
      "17                Hounslow    E09000018    14.295874    13.560026  -0.735848   \n",
      "18               Islington    E09000019    18.308749    20.568013   2.259264   \n",
      "19  Kensington and Chelsea    E09000020    21.433206    21.731359   0.298153   \n",
      "20    Kingston upon Thames    E09000021    14.384456    13.944801  -0.439655   \n",
      "21                 Lambeth    E09000022    17.242787    18.535245   1.292458   \n",
      "22                Lewisham    E09000023    14.290862    14.331798   0.040935   \n",
      "23                  Merton    E09000024    14.170024    14.593653   0.423629   \n",
      "24                  Newham    E09000025    14.389341    16.223485   1.834143   \n",
      "25               Redbridge    E09000026    12.374547    12.375257   0.000710   \n",
      "26    Richmond upon Thames    E09000027    15.877061    14.257492  -1.619569   \n",
      "27               Southwark    E09000028    16.172823    17.516394   1.343571   \n",
      "28                  Sutton    E09000029    10.113656    10.656790   0.543134   \n",
      "29           Tower Hamlets    E09000030    20.403332    22.956356   2.553024   \n",
      "30          Waltham Forest    E09000031    13.050069    13.489598   0.439528   \n",
      "31              Wandsworth    E09000032    18.560413    20.299919   1.739505   \n",
      "32             Westminster    E09000033    22.667469    23.928932   1.261464   \n",
      "\n",
      "    w_ratio11  w_ratio21     ethgr%  \n",
      "0    0.582020   0.449009  13.301165  \n",
      "1    0.640884   0.577284   6.359992  \n",
      "2    0.816123   0.718791   9.733167  \n",
      "3    0.361679   0.346362   1.531746  \n",
      "4    0.841295   0.764551   7.674403  \n",
      "5    0.662110   0.595157   6.695261  \n",
      "6    0.785898   0.693733   9.216578  \n",
      "7    0.550284   0.483679   6.660471  \n",
      "8    0.489049   0.431643   5.740571  \n",
      "9    0.609013   0.520884   8.812918  \n",
      "10   0.622933   0.556989   6.594426  \n",
      "11   0.544699   0.531393   1.330553  \n",
      "12   0.679506   0.631587   4.791823  \n",
      "13   0.603991   0.569869   3.412213  \n",
      "14   0.421700   0.364591   5.710932  \n",
      "15   0.875889   0.752957  12.293200  \n",
      "16   0.604838   0.481803  12.303506  \n",
      "17   0.513166   0.440983   7.218234  \n",
      "18   0.680907   0.622162   5.874553  \n",
      "19   0.705318   0.637456   6.786188  \n",
      "20   0.744246   0.683254   6.099240  \n",
      "21   0.570234   0.550222   2.001225  \n",
      "22   0.534563   0.514881   1.968241  \n",
      "23   0.647945   0.602346   4.559873  \n",
      "24   0.288177   0.307515  -1.933772  \n",
      "25   0.424798   0.348010   7.678814  \n",
      "26   0.859030   0.804555   5.447534  \n",
      "27   0.541433   0.514302   2.713081  \n",
      "28   0.784955   0.682826  10.212830  \n",
      "29   0.451184   0.394018   5.716629  \n",
      "30   0.520544   0.528050  -0.750621  \n",
      "31   0.713539   0.678125   3.541433  \n",
      "32   0.616483   0.551969   6.451415  \n"
     ]
    }
   ],
   "source": [
    "# Calculate the ratio for 2011\n",
    "eg2011['w_ratio11'] = eg2011['White'] / eg2011['All categories: Ethnic group']\n",
    "\n",
    "# Calculate the ratio for 2021\n",
    "eg2021['w_ratio21'] = eg2021['White'] / eg2021['Total: All usual residents']\n",
    "\n",
    "# Merge with gtr based on 'mnemonic' and 'borough code'\n",
    "gtr = gtr.merge(eg2011[['mnemonic', 'w_ratio11']], how='left', left_on='borough code', right_on='mnemonic')\n",
    "gtr = gtr.merge(eg2021[['mnemonic', 'w_ratio21']], how='left', left_on='borough code', right_on='mnemonic')\n",
    "\n",
    "# Drop redundant columns\n",
    "gtr = gtr.drop(columns=['mnemonic_x', 'mnemonic_y'])\n",
    "\n",
    "# add 'ethnic group%' column\n",
    "gtr['ethgr%'] = (gtr['w_ratio11'] - gtr['w_ratio21']) * 100\n",
    "print(gtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c940848b-83c8-408e-8673-926d41c5ae30",
   "metadata": {},
   "source": [
    "####  <span style=\"color:red\"> 1.2.3 h: Housing Price Change (Median/Average) </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a4ac81-9421-4445-af60-35f948ee9263",
   "metadata": {},
   "outputs": [],
   "source": [
    "## median price\n",
    "\n",
    "unique_values = price_med.index.unique()\n",
    "print(unique_values)\n",
    "# select data in 2011 and 2021\n",
    "Housing_med_df = pd.DataFrame()\n",
    "Housing_med_df ['median_2011'] =price_med.loc[:, ['Year ending Dec 2001']]\n",
    "Housing_med_df['median_2021'] =price_med.loc[:, ['Year ending Dec 2021']]\n",
    "Housing_med_df = Housing_med_df.groupby('Local authority code')[['median_2011', 'median_2021']].median()\n",
    "print(Housing_med_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5fd889da-0ddd-4ba7-9651-055dc06dbef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    E09000001  91448.98487  82202.77314  79120.70256  \\\n",
      "City of London                                                         \n",
      "Barking & Dagenham  E09000002  50460.22660  51085.77983  51268.96956   \n",
      "Barnet              E09000003  93284.51832  93190.16963  92247.52435   \n",
      "Bexley              E09000004  64958.09036  64787.92069  64367.49344   \n",
      "Brent               E09000005  71306.56698  72022.26197  72015.76274   \n",
      "Bromley             E09000006  81671.47692  81657.55944  81449.31143   \n",
      "\n",
      "                    77101.20804  84409.14932  94900.51244  110128.0423  \\\n",
      "City of London                                                           \n",
      "Barking & Dagenham  53133.50526  53042.24852  53700.34831  52113.12157   \n",
      "Barnet              90762.87492  90258.00033  90107.23471  91441.24768   \n",
      "Bexley              64277.66881  63997.13588  64252.32335  63722.70055   \n",
      "Brent               72965.63094  73704.04743  74310.48167  74127.03788   \n",
      "Bromley             81124.41227  81542.61561  82382.83435  82898.52264   \n",
      "\n",
      "                    112329.4376  104473.1096  ...    975240    963094  \\\n",
      "City of London                                ...                       \n",
      "Barking & Dagenham  52232.19868  51471.61353  ...  355596.0  353429.0   \n",
      "Barnet              92361.31512  93273.12245  ...  592328.0  596085.0   \n",
      "Bexley              64432.60005  64509.54767  ...  409059.0  402365.0   \n",
      "Brent               73547.04110  73789.54287  ...  552767.0  551093.0   \n",
      "Bromley             82054.37156  81440.43008  ...  512263.0  508434.0   \n",
      "\n",
      "                      869039    930986    903718    958418    951649  \\\n",
      "City of London                                                         \n",
      "Barking & Dagenham  346193.0  345288.0  348254.0  349590.0  346099.0   \n",
      "Barnet              602336.0  596064.0  587132.0  575141.0  575829.0   \n",
      "Bexley              403398.0  399796.0  398544.0  391077.0  390880.0   \n",
      "Brent               534129.0  525561.0  523992.0  524452.0  531478.0   \n",
      "Bromley             500974.0  495896.0  497632.0  496393.0  497841.0   \n",
      "\n",
      "                      931176    861107    807475  \n",
      "City of London                                    \n",
      "Barking & Dagenham  343430.0  344171.0  345614.0  \n",
      "Barnet              583479.0  597591.0  584740.0  \n",
      "Bexley              396718.0  396278.0  396292.0  \n",
      "Brent               531425.0  557552.0  565929.0  \n",
      "Bromley             503888.0  509263.0  502753.0  \n",
      "\n",
      "[5 rows x 346 columns]\n"
     ]
    }
   ],
   "source": [
    "print(housing_df.head(5)) # the row of 'city of london' as header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ee388-72c1-4a8e-a87b-85b5f95206fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## average price\n",
    "\n",
    "# set the index to datetime data\n",
    "housing_df.index = pd.to_datetime(housing_df.index, format='%Y%m%d')\n",
    "# set the column and index name\n",
    "housing_df.columns.name = 'London_borough'\n",
    "housing_df.index.name = 'year'\n",
    "# check the index(year) type\n",
    "print(housing_df.index.dtype)\n",
    "# select the london borough data\n",
    "London_housing_df = housing_df.filter(regex='^E09', axis=1)\n",
    "# change the column and index location \n",
    "London_housing_df = London_housing_df.transpose()\n",
    "# check the data\n",
    "London_housing_df.head(3) \n",
    "\n",
    "# select the data of 2011 and 2021\n",
    "housing_ave_df = pd.DataFrame()\n",
    "housing_ave_df ['average_2011'] =London_housing_df.loc[:, ['2011-12-01']]\n",
    "housing_ave_df ['average_2021'] =London_housing_df.loc[:, ['2012-12-01']]\n",
    "housing_ave_df.head(10) \n",
    "\n",
    "# link the median data and average data\n",
    "total_housing_df = pd.merge(housing_ave_df,Housing_med_df, left_index=True, right_index=True)\n",
    "# calculate the change of housing price\n",
    "total_housing_df['Compare_2011'] = total_housing_df['median_2011']/total_housing_df['average_2011']\n",
    "total_housing_df['Compare_2021'] = total_housing_df['median_2021']/total_housing_df['average_2021']\n",
    "total_housing_df['houseprice%'] = (total_housing_df['Compare_2021']-total_housing_df['Compare_2011']) / total_housing_df['Compare_2011']\n",
    "\n",
    "print(total_housing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39330e09-bc4d-4a7a-9919-8fb890812af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 'houseprice%' to 'gtr'\n",
    "gtr = pd.merge(gtr, total_housing_df['houseprice%'], left_on='borough code', right_on='???', how='left')\n",
    "# Drop the redundant 'Area code' column in 'gtr'\n",
    "gtr = gtr.drop('???', axis=1)\n",
    "print(gtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa5cd5f-e023-4e97-9dea-47435c499548",
   "metadata": {},
   "source": [
    "#### 1.2.4 d: Deprivation Proportion Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "06308f71-1a62-4321-b2fe-0f0dcee1d741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Area code dpr2011%   dpr2021%\n",
      "261  E09000007     37.9  47.523151\n",
      "262  E09000001       45  59.768010\n",
      "263  E09000012     31.5  44.952442\n",
      "264  E09000013     41.5  51.385949\n",
      "265  E09000014     35.7  43.316999\n",
      "266  E09000019     36.7  48.351227\n",
      "267  E09000020     43.6  52.589558\n",
      "268  E09000022     39.9  50.016334\n",
      "269  E09000023     38.4  47.211419\n",
      "270  E09000025       25  39.304111\n",
      "271  E09000028     36.2  48.546072\n",
      "272  E09000030     32.7  46.404898\n",
      "273  E09000032     50.4  58.362932\n",
      "274  E09000033     39.2  50.139746\n",
      "277  E09000002     28.2  37.591675\n",
      "278  E09000003     43.2  49.573264\n",
      "279  E09000004     41.5  48.518872\n",
      "280  E09000005     30.9  39.941996\n",
      "281  E09000006     48.5  54.642302\n",
      "282  E09000008       41  47.994717\n",
      "283  E09000009     37.4  46.034656\n",
      "284  E09000010     36.1  42.187397\n",
      "285  E09000011     37.2  48.243784\n",
      "286  E09000015     41.8  48.728275\n",
      "287  E09000016     39.7  47.298992\n",
      "288  E09000017     40.1  45.900319\n",
      "289  E09000018     37.3  44.100193\n",
      "290  E09000021     50.6  55.830006\n",
      "291  E09000024     46.5  53.906202\n",
      "292  E09000026     38.8  46.275780\n",
      "293  E09000027     57.6  61.038350\n",
      "294  E09000029     45.6  50.871909\n",
      "295  E09000031     34.3  45.262923\n"
     ]
    }
   ],
   "source": [
    "dpr2021_nodpr = dpr2021[dpr2021['Household deprivation (6 categories) Code'] == 1]\n",
    "dpr2021_all = dpr2021[(dpr2021['Household deprivation (6 categories) Code'] >= 1) & (dpr2021['Household deprivation (6 categories) Code'] <= 5)]\n",
    "sum = dpr2021_all.groupby('Upper tier local authorities Code')['Observation'].sum()\n",
    "\n",
    "ratios = (dpr2021_nodpr.groupby('Upper tier local authorities Code')['Observation'].sum() / sum) * 100\n",
    "\n",
    "# Create a new DataFrame by merging 'dpr2011' and 'ratios'\n",
    "result_df = pd.merge(dpr2011, ratios, left_on='Area code', right_index=True, how='left')\n",
    "result_df = result_df.rename(columns={'Observation': 'dpr2021%',\n",
    "                                      'Household is not deprived in any dimension': 'dpr2011%'})\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "248e5733-27c4-41f5-ba3f-2a477045142b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   borough borough code  2011moving%  2021moving%  popchurn%  \\\n",
      "0     Barking and Dagenham    E09000002    11.314102    11.096466  -0.217636   \n",
      "1                   Barnet    E09000003    13.528176    13.449671  -0.078505   \n",
      "2                   Bexley    E09000004     8.559739     9.228325   0.668586   \n",
      "3                    Brent    E09000005    14.025929    15.189397   1.163468   \n",
      "4                  Bromley    E09000006    10.936476    10.685033  -0.251443   \n",
      "5                   Camden    E09000007    19.379820    21.068651   1.688831   \n",
      "6           City of London    E09000001    27.085688    32.213164   5.127475   \n",
      "7                  Croydon    E09000008    11.519518    11.934819   0.415301   \n",
      "8                   Ealing    E09000009    13.772567    14.096957   0.324390   \n",
      "9                  Enfield    E09000010    12.009192    10.912710  -1.096482   \n",
      "10               Greenwich    E09000011    14.079714    13.880816  -0.198898   \n",
      "11                 Hackney    E09000012    15.340250    17.696536   2.356286   \n",
      "12  Hammersmith and Fulham    E09000013    19.660653    21.308668   1.648015   \n",
      "13                Haringey    E09000014    16.727549    15.956565  -0.770984   \n",
      "14                  Harrow    E09000015    11.357007    12.182632   0.825626   \n",
      "15                Havering    E09000016     8.166717     9.618064   1.451346   \n",
      "16              Hillingdon    E09000017    11.185262    11.658885   0.473623   \n",
      "17                Hounslow    E09000018    14.295874    13.560026  -0.735848   \n",
      "18               Islington    E09000019    18.308749    20.568013   2.259264   \n",
      "19  Kensington and Chelsea    E09000020    21.433206    21.731359   0.298153   \n",
      "20    Kingston upon Thames    E09000021    14.384456    13.944801  -0.439655   \n",
      "21                 Lambeth    E09000022    17.242787    18.535245   1.292458   \n",
      "22                Lewisham    E09000023    14.290862    14.331798   0.040935   \n",
      "23                  Merton    E09000024    14.170024    14.593653   0.423629   \n",
      "24                  Newham    E09000025    14.389341    16.223485   1.834143   \n",
      "25               Redbridge    E09000026    12.374547    12.375257   0.000710   \n",
      "26    Richmond upon Thames    E09000027    15.877061    14.257492  -1.619569   \n",
      "27               Southwark    E09000028    16.172823    17.516394   1.343571   \n",
      "28                  Sutton    E09000029    10.113656    10.656790   0.543134   \n",
      "29           Tower Hamlets    E09000030    20.403332    22.956356   2.553024   \n",
      "30          Waltham Forest    E09000031    13.050069    13.489598   0.439528   \n",
      "31              Wandsworth    E09000032    18.560413    20.299919   1.739505   \n",
      "32             Westminster    E09000033    22.667469    23.928932   1.261464   \n",
      "\n",
      "    w_ratio11  w_ratio21     ethgr% dpr2011%   dpr2021%  \n",
      "0    0.582020   0.449009  13.301165     28.2  37.591675  \n",
      "1    0.640884   0.577284   6.359992     43.2  49.573264  \n",
      "2    0.816123   0.718791   9.733167     41.5  48.518872  \n",
      "3    0.361679   0.346362   1.531746     30.9  39.941996  \n",
      "4    0.841295   0.764551   7.674403     48.5  54.642302  \n",
      "5    0.662110   0.595157   6.695261     37.9  47.523151  \n",
      "6    0.785898   0.693733   9.216578       45  59.768010  \n",
      "7    0.550284   0.483679   6.660471       41  47.994717  \n",
      "8    0.489049   0.431643   5.740571     37.4  46.034656  \n",
      "9    0.609013   0.520884   8.812918     36.1  42.187397  \n",
      "10   0.622933   0.556989   6.594426     37.2  48.243784  \n",
      "11   0.544699   0.531393   1.330553     31.5  44.952442  \n",
      "12   0.679506   0.631587   4.791823     41.5  51.385949  \n",
      "13   0.603991   0.569869   3.412213     35.7  43.316999  \n",
      "14   0.421700   0.364591   5.710932     41.8  48.728275  \n",
      "15   0.875889   0.752957  12.293200     39.7  47.298992  \n",
      "16   0.604838   0.481803  12.303506     40.1  45.900319  \n",
      "17   0.513166   0.440983   7.218234     37.3  44.100193  \n",
      "18   0.680907   0.622162   5.874553     36.7  48.351227  \n",
      "19   0.705318   0.637456   6.786188     43.6  52.589558  \n",
      "20   0.744246   0.683254   6.099240     50.6  55.830006  \n",
      "21   0.570234   0.550222   2.001225     39.9  50.016334  \n",
      "22   0.534563   0.514881   1.968241     38.4  47.211419  \n",
      "23   0.647945   0.602346   4.559873     46.5  53.906202  \n",
      "24   0.288177   0.307515  -1.933772       25  39.304111  \n",
      "25   0.424798   0.348010   7.678814     38.8  46.275780  \n",
      "26   0.859030   0.804555   5.447534     57.6  61.038350  \n",
      "27   0.541433   0.514302   2.713081     36.2  48.546072  \n",
      "28   0.784955   0.682826  10.212830     45.6  50.871909  \n",
      "29   0.451184   0.394018   5.716629     32.7  46.404898  \n",
      "30   0.520544   0.528050  -0.750621     34.3  45.262923  \n",
      "31   0.713539   0.678125   3.541433     50.4  58.362932  \n",
      "32   0.616483   0.551969   6.451415     39.2  50.139746  \n"
     ]
    }
   ],
   "source": [
    "# Merge 'result_df' with 'gtr'\n",
    "gtr = pd.merge(gtr, result_df[['Area code', 'dpr2011%', 'dpr2021%']], left_on='borough code', right_on='Area code', how='left')\n",
    "# Drop the redundant 'Area code' column in 'gtr'\n",
    "gtr = gtr.drop('Area code', axis=1)\n",
    "\n",
    "print(gtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7467b0b6-25ab-4069-a2c4-3ba95f1dfc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   borough borough code  2011moving%  2021moving%  popchurn%  \\\n",
      "0     Barking and Dagenham    E09000002    11.314102    11.096466  -0.217636   \n",
      "1                   Barnet    E09000003    13.528176    13.449671  -0.078505   \n",
      "2                   Bexley    E09000004     8.559739     9.228325   0.668586   \n",
      "3                    Brent    E09000005    14.025929    15.189397   1.163468   \n",
      "4                  Bromley    E09000006    10.936476    10.685033  -0.251443   \n",
      "5                   Camden    E09000007    19.379820    21.068651   1.688831   \n",
      "6           City of London    E09000001    27.085688    32.213164   5.127475   \n",
      "7                  Croydon    E09000008    11.519518    11.934819   0.415301   \n",
      "8                   Ealing    E09000009    13.772567    14.096957   0.324390   \n",
      "9                  Enfield    E09000010    12.009192    10.912710  -1.096482   \n",
      "10               Greenwich    E09000011    14.079714    13.880816  -0.198898   \n",
      "11                 Hackney    E09000012    15.340250    17.696536   2.356286   \n",
      "12  Hammersmith and Fulham    E09000013    19.660653    21.308668   1.648015   \n",
      "13                Haringey    E09000014    16.727549    15.956565  -0.770984   \n",
      "14                  Harrow    E09000015    11.357007    12.182632   0.825626   \n",
      "15                Havering    E09000016     8.166717     9.618064   1.451346   \n",
      "16              Hillingdon    E09000017    11.185262    11.658885   0.473623   \n",
      "17                Hounslow    E09000018    14.295874    13.560026  -0.735848   \n",
      "18               Islington    E09000019    18.308749    20.568013   2.259264   \n",
      "19  Kensington and Chelsea    E09000020    21.433206    21.731359   0.298153   \n",
      "20    Kingston upon Thames    E09000021    14.384456    13.944801  -0.439655   \n",
      "21                 Lambeth    E09000022    17.242787    18.535245   1.292458   \n",
      "22                Lewisham    E09000023    14.290862    14.331798   0.040935   \n",
      "23                  Merton    E09000024    14.170024    14.593653   0.423629   \n",
      "24                  Newham    E09000025    14.389341    16.223485   1.834143   \n",
      "25               Redbridge    E09000026    12.374547    12.375257   0.000710   \n",
      "26    Richmond upon Thames    E09000027    15.877061    14.257492  -1.619569   \n",
      "27               Southwark    E09000028    16.172823    17.516394   1.343571   \n",
      "28                  Sutton    E09000029    10.113656    10.656790   0.543134   \n",
      "29           Tower Hamlets    E09000030    20.403332    22.956356   2.553024   \n",
      "30          Waltham Forest    E09000031    13.050069    13.489598   0.439528   \n",
      "31              Wandsworth    E09000032    18.560413    20.299919   1.739505   \n",
      "32             Westminster    E09000033    22.667469    23.928932   1.261464   \n",
      "\n",
      "    w_ratio11  w_ratio21     ethgr% dpr2011%   dpr2021%       dpr%  \n",
      "0    0.582020   0.449009  13.301165     28.2  37.591675  -9.391675  \n",
      "1    0.640884   0.577284   6.359992     43.2  49.573264  -6.373264  \n",
      "2    0.816123   0.718791   9.733167     41.5  48.518872  -7.018872  \n",
      "3    0.361679   0.346362   1.531746     30.9  39.941996  -9.041996  \n",
      "4    0.841295   0.764551   7.674403     48.5  54.642302  -6.142302  \n",
      "5    0.662110   0.595157   6.695261     37.9  47.523151  -9.623151  \n",
      "6    0.785898   0.693733   9.216578       45  59.768010  -14.76801  \n",
      "7    0.550284   0.483679   6.660471       41  47.994717  -6.994717  \n",
      "8    0.489049   0.431643   5.740571     37.4  46.034656  -8.634656  \n",
      "9    0.609013   0.520884   8.812918     36.1  42.187397  -6.087397  \n",
      "10   0.622933   0.556989   6.594426     37.2  48.243784 -11.043784  \n",
      "11   0.544699   0.531393   1.330553     31.5  44.952442 -13.452442  \n",
      "12   0.679506   0.631587   4.791823     41.5  51.385949  -9.885949  \n",
      "13   0.603991   0.569869   3.412213     35.7  43.316999  -7.616999  \n",
      "14   0.421700   0.364591   5.710932     41.8  48.728275  -6.928275  \n",
      "15   0.875889   0.752957  12.293200     39.7  47.298992  -7.598992  \n",
      "16   0.604838   0.481803  12.303506     40.1  45.900319  -5.800319  \n",
      "17   0.513166   0.440983   7.218234     37.3  44.100193  -6.800193  \n",
      "18   0.680907   0.622162   5.874553     36.7  48.351227 -11.651227  \n",
      "19   0.705318   0.637456   6.786188     43.6  52.589558  -8.989558  \n",
      "20   0.744246   0.683254   6.099240     50.6  55.830006  -5.230006  \n",
      "21   0.570234   0.550222   2.001225     39.9  50.016334 -10.116334  \n",
      "22   0.534563   0.514881   1.968241     38.4  47.211419  -8.811419  \n",
      "23   0.647945   0.602346   4.559873     46.5  53.906202  -7.406202  \n",
      "24   0.288177   0.307515  -1.933772       25  39.304111 -14.304111  \n",
      "25   0.424798   0.348010   7.678814     38.8  46.275780   -7.47578  \n",
      "26   0.859030   0.804555   5.447534     57.6  61.038350   -3.43835  \n",
      "27   0.541433   0.514302   2.713081     36.2  48.546072 -12.346072  \n",
      "28   0.784955   0.682826  10.212830     45.6  50.871909  -5.271909  \n",
      "29   0.451184   0.394018   5.716629     32.7  46.404898 -13.704898  \n",
      "30   0.520544   0.528050  -0.750621     34.3  45.262923 -10.962923  \n",
      "31   0.713539   0.678125   3.541433     50.4  58.362932  -7.962932  \n",
      "32   0.616483   0.551969   6.451415     39.2  50.139746 -10.939746  \n"
     ]
    }
   ],
   "source": [
    "# add deprivation change to 'gtr'\n",
    "gtr['dpr%'] = gtr['dpr2011%'] - gtr['dpr2021%']\n",
    "print(gtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965dd34d-5177-47ba-a90b-2e1df6f47fff",
   "metadata": {},
   "source": [
    "#### 1.2.5  Gentrification Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2f9a8b-a303-4265-bf43-5ac6a8b83959",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtr['score'] = (1/2*gtr['popchurn%'] - 1/4*gtr['ethgr%'] \n",
    "                + 1/8*gtr['houseprice%'] -1/8*gtr['dpr%']) + 0.25\n",
    "print(gtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9af3225-bfd5-4c0c-8752-8f13c614e307",
   "metadata": {},
   "source": [
    "### 1.3 Airbnb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9c1e3c81-82df-47c3-ad08-664260663b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Data/listings.csv.gz locally!\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: 'Data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m     dataframes[url] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(dest)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m url\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     dataframes[url] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgzip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:755\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[1;32m    754\u001b[0m         \u001b[38;5;66;03m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;00m\n\u001b[0;32m--> 755\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[43mgzip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGzipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[1;32m    756\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompression_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m         handle \u001b[38;5;241m=\u001b[39m gzip\u001b[38;5;241m.\u001b[39mGzipFile(\n\u001b[1;32m    762\u001b[0m             \u001b[38;5;66;03m# No overload variant of \"GzipFile\" matches argument types\u001b[39;00m\n\u001b[1;32m    763\u001b[0m             \u001b[38;5;66;03m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcompression_args,\n\u001b[1;32m    767\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/gzip.py:174\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    172\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmyfileobj \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fileobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: 'Data'"
     ]
    }
   ],
   "source": [
    "urls = ['http://data.insideairbnb.com/united-kingdom/england/london/2022-12-10/data/listings.csv.gz',\n",
    "      'http://data.insideairbnb.com/united-kingdom/england/london/2022-12-10/visualisations/neighbourhoods.csv',\n",
    "      'http://data.insideairbnb.com/united-kingdom/england/london/2022-12-10/data/calendar.csv.gz',\n",
    "      'http://data.insideairbnb.com/united-kingdom/england/london/2022-12-10/data/reviews.csv.gz']\n",
    "dest = 'Data/'\n",
    "files = ['listings.csv.gz']\n",
    "\n",
    "# download and open files\n",
    "for url, file in urls, files:\n",
    "    cache_data(url,dest)\n",
    "    if file.endswith(\".csv\"):\n",
    "        dataframes[file] = pd.read_csv(dest)\n",
    "    elif file.endswith(\".csv.gz\"):\n",
    "        dataframes[file] = pd.read_csv(dest, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344abe29-adb7-410e-be2b-dad4ae25f5b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794758a0-712a-40e4-8150-c5f8615c91d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed3a92d-d04b-4315-9ba7-374455ec6ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data source\n",
    "# https://cycling.data.tfl.gov.uk/\n",
    "\n",
    "# files saved under Data/ActiveTravelCounts\n",
    "dir = 'Data/ActiveTravelCounts'\n",
    "# raw files\n",
    "loc_raw = '0-Count locations.csv'\n",
    "central_raw = '2022-Central.csv'\n",
    "inner_raw1 = '2022-Inner-Part1.csv'\n",
    "inner_raw2 = '2022-Inner-Part2.csv'\n",
    "outer_raw = '2022-Outer.csv'\n",
    "# saved file name\n",
    "location_fn = 'count_locations.geoparquet'\n",
    "travelcounts_fn = 'travel_counts.parquet'\n",
    "\n",
    "# geodataframe for points data will be saved as loc_gdf\n",
    "# dataframe for counts will be saved as counts_df\n",
    "\n",
    "# load the points data\n",
    "\n",
    "# check if gpkg file already exists\n",
    "# if not, convert the raw file into geoparquet after reading it in\n",
    "if not os.path.exists(os.path.join(dir, location_fn)):\n",
    "    print(\"Loading locations from csv and saving as geoparquet\")\n",
    "    loc_df = pd.read_csv(os.path.join(dir, loc_raw))\n",
    "    loc_gdf = gpd.GeoDataFrame(loc_df, geometry = gpd.points_from_xy(loc_df['Easting (UK Grid)'], loc_df['Northing (UK Grid)'], crs = 'EPSG:27700'))\n",
    "    # convert Functional area for monitoring into category\n",
    "    loc_gdf['Functional area for monitoring'] = loc_gdf['Functional area for monitoring'].astype('category')\n",
    "    loc_gdf.to_parquet(os.path.join(dir, location_fn))\n",
    "\n",
    "# if file already there, load from gpkg\n",
    "else:\n",
    "    print(\"Loading locations from processed geoparquet\")\n",
    "    loc_gdf = gpd.read_parquet(os.path.join(dir, location_fn))\n",
    "\n",
    "print(\"Location load complete. Use loc_gdf\")\n",
    "\n",
    "# load the travel counts data\n",
    "# check if file already exists\n",
    "# if not, load from csv and save the chunk before analysis\n",
    "\n",
    "if not os.path.exists(os.path.join(dir, travelcounts_fn)):\n",
    "    print(\"Loading counts from CSV and cleaning data\")\n",
    "\n",
    "    # load files\n",
    "    cen_df = pd.read_csv(os.path.join(dir, central_raw))\n",
    "    in1_df = pd.read_csv(os.path.join(dir, inner_raw1))\n",
    "    in2_df = pd.read_csv(os.path.join(dir, inner_raw2))\n",
    "    out_df = pd.read_csv(os.path.join(dir, outer_raw))\n",
    "\n",
    "    # add zone\n",
    "    cen_df.insert(2, 'Zone', 'Central')\n",
    "    in1_df.insert(2, 'Zone', 'Inner')\n",
    "    in2_df.insert(2, 'Zone', 'Inner')\n",
    "    out_df.insert(2, 'Zone', 'Outer')\n",
    "\n",
    "    # join data frames\n",
    "    counts_df = pd.concat([cen_df, in1_df, in2_df, out_df])\n",
    "\n",
    "    # clean data\n",
    "    # insert datetime column in datetime format\n",
    "    counts_df.insert(3, 'datetime', pd.to_datetime(counts_df['Date'] + ' ' + counts_df['Time'], dayfirst = True))\n",
    "    \n",
    "    # turn into categorical data\n",
    "    categorical = ['Zone', 'Weather', 'Day', 'Round', 'Dir', 'Path', 'Mode']\n",
    "    \n",
    "    for c in categorical:\n",
    "        counts_df[c] = counts_df[c].astype('category')\n",
    "\n",
    "    # save parquet file\n",
    "    counts_df.to_parquet(os.path.join(dir, travelcounts_fn))\n",
    "\n",
    "# if file already there, load from parquet\n",
    "else:\n",
    "    print(\"Loading counts from processed parquet\")\n",
    "    counts_df = pd.read_parquet(os.path.join(dir, travelcounts_fn))\n",
    "\n",
    "print(\"Counts load complete. Use counts_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acce81c-8a5a-4a18-a101-436dfcf365f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Looking at the `loc_gdf` Geodataframe\n",
    "\n",
    "Check to confirm file loading is done correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0981240d-d0c2-4dff-8eb4-969286ce06ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 2297 entries, 0 to 2296\n",
      "Data columns (total 13 columns):\n",
      " #   Column                             Non-Null Count  Dtype   \n",
      "---  ------                             --------------  -----   \n",
      " 0   Site ID                            2297 non-null   object  \n",
      " 1   Which folder?                      2297 non-null   object  \n",
      " 2   Shared sites                       2297 non-null   object  \n",
      " 3   Location description               2297 non-null   object  \n",
      " 4   Borough                            2297 non-null   object  \n",
      " 5   Functional area for monitoring     2297 non-null   category\n",
      " 6   Road type                          2297 non-null   object  \n",
      " 7   Is it on the strategic CIO panel?  2297 non-null   int64   \n",
      " 8   Easting (UK Grid)                  2297 non-null   float64 \n",
      " 9   Northing (UK Grid)                 2297 non-null   float64 \n",
      " 10  Latitude                           2297 non-null   float64 \n",
      " 11  Longitude                          2297 non-null   float64 \n",
      " 12  geometry                           2297 non-null   geometry\n",
      "dtypes: category(1), float64(4), geometry(1), int64(1), object(6)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "loc_gdf.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
