{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1efb9da3-ff66-48c4-9760-b55425017d70",
   "metadata": {},
   "source": [
    "# FSDS Group Assessment (Group Safari)\n",
    "\n",
    "## 1. Data Collection and Cleaning\n",
    "We will use 2 different datasets:\n",
    "1. Airbnb data of London (10 Dec, 2022) downloading from [InsideAirbnb](http://insideairbnb.com/get-the-data)  \n",
    "2. 2011 and 2021 Census data including:\n",
    "* popchurn 11.csv\n",
    "* MIG009EW_LTLA_OUT.csv\n",
    "* MIG009EW_LTLA_IN.csv\n",
    "* ethnic group 2011.csv\n",
    "* ethnic group 2021.csv\n",
    "* house price_median.xls\n",
    "* house price_aver.xlsx\n",
    "* Deprivation 2011.xls\n",
    "* Deprivation 2021.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900b1c81-c4e8-44ec-bd43-9ecb7886b2bc",
   "metadata": {},
   "source": [
    "### 1.1 Input data and create dataframe\n",
    "\n",
    "Note that all data in the Data subdirectory is ignored in the `.gitignore` file.\n",
    "\n",
    "The file names that are used in this script are as follows.\n",
    "\n",
    "|Data Type|File Name|df/gdf name|Gentrification Score df Name|Note|\n",
    "|:---|:---|:---|:--|:--|\n",
    "||`popchurn 11.csv`|`popch2011`|`2011moving%`||\n",
    "||`MIG009EW_LTLA_OUT.csv`|`moving2021`|`2021moving%`||\n",
    "||`MIG009EW_LTLA_IN.csv`||||\n",
    "||`ethnic group 2011.csv`|`eg2011`|`w_ratio11`||\n",
    "||`ethnic group 2021.csv`|`eg2021`|`w_ratio21`||\n",
    "||`house price_median.xls`|`price_med`|`houseprice%`||\n",
    "||`house price_aver.xlsx`|`housing_df`|||\n",
    "||`Deprivation 2011.xls`|`dpr2011`|`dpr2011%`||\n",
    "||`Deprivation 2021.csv`|`dpr2021`|`dpr2021%`||\n",
    "|`multipolygon`|`Boroughs.gpkg`|`boros`||`crs:27700`|\n",
    "|`Airbnb listing`|`listings.csv.gz`|`ls`|`\\`||\n",
    "|`Airbnb listing -> geopandas`|`\\`|`gls`|`\\`|`crs:27700`|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821697a0-b2bf-46a6-b94e-5ff111171ffa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1.1.1 Get Prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d77d5c-c664-4d78-a926-4b4d32dc68c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<jemalloc>: MADV_DONTNEED does not work (memset will be used instead)\n",
      "<jemalloc>: (This is the expected behaviour if you are running under QEMU)\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "from requests import get\n",
    "from urllib.parse import urlparse\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3951fa7b-2975-4e9f-8df7-6170dfc70b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from remote location\n",
    "def cache_data(src:str, dest:str) -> str:\n",
    "    \"\"\"Downloads and caches a remote file locally.\n",
    "    \n",
    "    The function sits between the 'read' step of a pandas or geopandas\n",
    "    data frame and downloading the file from a remote location. The idea\n",
    "    is that it will save it locally so that you don't need to remember to\n",
    "    do so yourself. Subsequent re-reads of the file will return instantly\n",
    "    rather than downloading the entire file for a second or n-th itme.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    src : str\n",
    "        The remote *source* for the file, any valid URL should work.\n",
    "    dest : str\n",
    "        The *destination* location to save the downloaded file.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A string representing the local location of the file.\n",
    "    \"\"\"\n",
    "    url = urlparse(src) # We assume that this is some kind of valid URL \n",
    "    fn  = os.path.split(url.path)[-1] # Extract the filename\n",
    "    dfn = os.path.join(dest,fn) #Â Destination filename\n",
    "    \n",
    "    if not os.path.isfile(dfn):\n",
    "        \n",
    "        print(f\"{dfn} not found, downloading!\")\n",
    "\n",
    "        path = os.path.split(dest)\n",
    "        \n",
    "        if len(path) >= 1 and path[0] != '':\n",
    "            os.makedirs(os.path.join(*path), exist_ok=True)\n",
    "            \n",
    "        with open(dfn, \"wb\") as file:\n",
    "            response = get(src)\n",
    "            file.write(response.content)\n",
    "            \n",
    "        print(\"\\tDone downloading...\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Found {dfn} locally!\")\n",
    "\n",
    "    return dfn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed83e647-0164-42e2-a536-44db194e955e",
   "metadata": {},
   "source": [
    "Please save data files under directory: ***Data/*** which is in the same level as this ipynb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9336107a-6380-4e54-8fbf-7a6a1bd8a712",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#local_repo_dir = 'Documents/casa/fsds/group' # change this to your own directory under 'work'\n",
    "# os.chdir('/home/jovyan/work/' + local_repo_dir)\n",
    "padir = 'Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e02b44-85ed-4063-92d6-0bef107c259f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1.1.2 Read Files and Select Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8998b0b0-7250-45bd-be25-eb3532999c61",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**For now, I am using local files(which are under folder \"Data\"), but I'll adjust it later to download directly using url.** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2415063f-5b91-40f9-a779-43802758efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Population Churn\n",
    "popch2011 = pd.read_csv(padir+'popchurn 11.csv', skiprows=7, skip_blank_lines=True, usecols=[\n",
    "    'local authority: district / unitary (prior to April 2015)',\n",
    "    'mnemonic',\n",
    "    'Whole household lived at same address one year ago', \n",
    "    'Wholly moving household: Total']).dropna(how='all').iloc[:33]\n",
    "\n",
    "popch2021_in_raw = pd.read_csv(padir + 'MIG009EW_LTLA_IN.csv', usecols=['Lower tier local authorities code', 'Household migration LTLA (inflow) (7 categories) code', 'Count'])\n",
    "popch2021_out_raw = pd.read_csv(padir + 'MIG009EW_LTLA_OUT.csv', usecols=['Migrant LTLA one year ago code', 'Household migration LTLA (outflow) (3 categories) code', 'Count'])\n",
    "\n",
    "popch2021_in = popch2021_in_raw.loc[popch2021_in_raw['Lower tier local authorities code'].astype(str).str.match(r'^E090000[0-9]{2}$|^E09000[1-3][0-3]$', na=False)]\n",
    "popch2021_out = popch2021_out_raw.loc[popch2021_out_raw['Migrant LTLA one year ago code'].astype(str).str.match(r'^E090000[0-9]{2}$|^E09000[1-3][0-3]$', na=False)]\n",
    "\n",
    "## Ethnic Group\n",
    "eg2011 = pd.read_csv(padir+'ethnic group 2011.csv', skiprows=7, header=0, skip_blank_lines=True, usecols=[\n",
    "    'mnemonic','All categories: Ethnic group','White'])\n",
    "eg2021 = pd.read_csv(padir+'ethnic group 2021.csv', skiprows=6, header=0, skip_blank_lines=True, usecols=[\n",
    "    'mnemonic','Total: All usual residents','White'])\n",
    "\n",
    "## Housing price\n",
    "# median housing price\n",
    "price_med_raw = pd.read_excel(padir+'house price_median.xls',sheet_name='1a',engine='xlrd',skiprows=5,header=0,usecols=[\n",
    "    'Local authority code','Year ending Dec 2001','Year ending Dec 2021'])\n",
    "price_med = price_med_raw.loc[price_med_raw['Local authority code'].astype(str).str.contains(r'^E09', regex=True)]\n",
    "price_med.set_index('Local authority code', inplace=True)\n",
    "# average housing price \n",
    "housing_price = \"house price_aver.xlsx\"\n",
    "housing_df = pd.read_excel(os.path.join(padir, housing_price),sheet_name=2,skiprows=1, header=0,index_col=0)\n",
    "\n",
    "## Deprivation\n",
    "dpr2011_raw = pd.read_excel(padir+'deprivation 2011.xls',sheet_name='QS119EW_Percentages',engine='xlrd',skiprows=10,header=0, usecols=[\n",
    "    'Area code','Household is not deprived in any dimension'])\n",
    "dpr2011 = dpr2011_raw.loc[dpr2011_raw['Area code'].astype(str).str.contains(r'^E090000[0-2][0-9]$|^E090003[0-3]$|^E090000[1-9][0-9]$|^E09000[1-3][0-3]$'\n",
    ", regex=True)]\n",
    "\n",
    "dpr2021_raw = pd.read_csv(padir+'deprivation 2021.csv')\n",
    "dpr2021 = dpr2021_raw[dpr2021_raw['Upper tier local authorities Code'].astype(str).str.contains(\n",
    "    r'^E090000[0-2][0-9]$|^E090003[0-3]$|^E090000[1-9][0-9]$|^E09000[1-3][0-3]$', regex=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2cdf89-e0b7-4015-b883-c9a0c383cdc5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.2 Calculate Gentrification Score\n",
    "G = 1/2c - 1/4e + 1/8h - 1/8d + 0.25  \n",
    "    c: population churn at household level - the ratio of the households that have changed  \n",
    "    e: ethnic group - the change of the proportion of non-white residents  \n",
    "    h: housing price - relative change in median house price compared with acerage price  \n",
    "    d: deprivation - relative change in the proportion of households with deprivation dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148638a6-e664-40f6-b64d-71cb9621252b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79998c96-c5b5-471d-b818-8646baa48486",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1.2.1   c: Population Churn (Household Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400146d2-1e09-4dfd-9e0b-7094d605a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtr = pd.DataFrame()\n",
    "## 2011 moving households\n",
    "popch2011['2011moving%'] = (100*\n",
    "    (popch2011['Wholly moving household: Total'] /\n",
    "    (popch2011['Wholly moving household: Total'] + popch2011['Whole household lived at same address one year ago'])))\n",
    "\n",
    "gtr['borough'] = popch2011['local authority: district / unitary (prior to April 2015)']\n",
    "gtr['borough code'] = popch2011['mnemonic']\n",
    "gtr['2011moving%'] = popch2011['2011moving%']\n",
    "print(gtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf04250-b51b-433a-aa76-dbc93118d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2022 moving households\n",
    "# population churn = moving household / all household =  moving household / (not moving household +  moving household)\n",
    "samead = popch2021_in.loc[popch2021_in['Household migration LTLA (inflow) (7 categories) code'] == 1].groupby('Lower tier local authorities code')['Count'].sum().reset_index()\n",
    "movein = popch2021_in.loc[(popch2021_in['Household migration LTLA (inflow) (7 categories) code'] >= 2) & (popch2021_in['Household migration LTLA (inflow) (7 categories) code'] <= 5)].groupby('Lower tier local authorities code')['Count'].sum().reset_index()\n",
    "moveout = popch2021_out.loc[(popch2021_out['Household migration LTLA (outflow) (3 categories) code'] >= 1) & (popch2021_out['Household migration LTLA (outflow) (3 categories) code'] <= 2)].groupby('Migrant LTLA one year ago code')['Count'].sum().reset_index()\n",
    "\n",
    "samead = samead.rename(columns={'Lower tier local authorities code': 'code'})\n",
    "movein = movein.rename(columns={'Lower tier local authorities code': 'code'})\n",
    "moveout = moveout.rename(columns={'Migrant LTLA one year ago code': 'code'})\n",
    "print(samead.head(5))\n",
    "moving2021 = (\n",
    "    (movein.set_index('code')['Count'] +moveout.set_index('code')['Count']) /\n",
    "    (samead.set_index('code')['Count'] + movein.set_index('code')['Count'] + moveout.set_index('code')['Count'])\n",
    ").reset_index(name='2021moving%') * 100\n",
    "print(moving2021.head(5))\n",
    "\n",
    "# Extract the first part of 'code' in moving2021\n",
    "moving2021['code'] = moving2021['code'].str.slice(0, 9)\n",
    "\n",
    "# Merge the result into gtr based on 'borough code' and 'code'\n",
    "gtr = gtr.merge(moving2021, how='left', left_on='borough code', right_on='code',suffixes=('', '_y'))\n",
    "\n",
    "# Drop the redundant 'code' column\n",
    "gtr = gtr.drop(columns=['code'])\n",
    "\n",
    "# add 'popchurn' column: \n",
    "gtr['popchurn%'] = gtr['2021moving%'] - gtr['2011moving%']\n",
    "# Display the resulting DataFrame gtr\n",
    "print(gtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19ee372-38ba-498d-8bb4-85964a7d5190",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1.2.2 e: Non-white Ethnic Group Proportion Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62439c8e-cb74-4cf9-a4e9-6728c2746533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the ratio for 2011\n",
    "eg2011['w_ratio11'] = eg2011['White'] / eg2011['All categories: Ethnic group']\n",
    "\n",
    "# Calculate the ratio for 2021\n",
    "eg2021['w_ratio21'] = eg2021['White'] / eg2021['Total: All usual residents']\n",
    "\n",
    "# Merge with gtr based on 'mnemonic' and 'borough code'\n",
    "gtr = gtr.merge(eg2011[['mnemonic', 'w_ratio11']], how='left', left_on='borough code', right_on='mnemonic')\n",
    "gtr = gtr.merge(eg2021[['mnemonic', 'w_ratio21']], how='left', left_on='borough code', right_on='mnemonic')\n",
    "\n",
    "# Drop redundant columns\n",
    "gtr = gtr.drop(columns=['mnemonic_x', 'mnemonic_y'])\n",
    "\n",
    "# add 'ethnic group%' column\n",
    "gtr['ethgr%'] = (gtr['w_ratio11'] - gtr['w_ratio21']) * 100\n",
    "print(gtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c940848b-83c8-408e-8673-926d41c5ae30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "####  <span style=\"color:red\"> 1.2.3 h: Housing Price Change (Median/Average) </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3a4ac81-9421-4445-af60-35f948ee9263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['E09000002', 'E09000003', 'E09000004', 'E09000005', 'E09000006',\n",
      "       'E09000007', 'E09000001', 'E09000008', 'E09000009', 'E09000010',\n",
      "       'E09000011', 'E09000012', 'E09000013', 'E09000014', 'E09000015',\n",
      "       'E09000016', 'E09000017', 'E09000018', 'E09000019', 'E09000020',\n",
      "       'E09000021', 'E09000022', 'E09000023', 'E09000024', 'E09000025',\n",
      "       'E09000026', 'E09000027', 'E09000028', 'E09000029', 'E09000030',\n",
      "       'E09000031', 'E09000032', 'E09000033'],\n",
      "      dtype='object', name='Local authority code')\n",
      "                      median_2011  median_2021\n",
      "Local authority code                          \n",
      "E09000001               237500.00     797500.0\n",
      "E09000002                87871.25     333750.0\n",
      "E09000003               185000.00     600000.0\n",
      "E09000004               119983.75     394000.0\n",
      "E09000005               158656.25     509250.0\n",
      "E09000006               158500.00     490000.0\n",
      "E09000007               249725.00     808125.0\n",
      "E09000008               125000.00     398750.0\n",
      "E09000009               165000.00     520000.0\n",
      "E09000010               131000.00     440250.0\n"
     ]
    }
   ],
   "source": [
    "## median price\n",
    "\n",
    "unique_values = price_med.index.unique()\n",
    "print(unique_values)\n",
    "# select data in 2011 and 2021\n",
    "Housing_med_df = pd.DataFrame()\n",
    "Housing_med_df ['median_2011'] =price_med.loc[:, ['Year ending Dec 2001']]\n",
    "Housing_med_df['median_2021'] =price_med.loc[:, ['Year ending Dec 2021']]\n",
    "Housing_med_df = Housing_med_df.groupby('Local authority code')[['median_2011', 'median_2021']].median()\n",
    "print(Housing_med_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fd889da-0ddd-4ba7-9651-055dc06dbef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    E09000001  91448.98487  82202.77314  79120.70256  \\\n",
      "City of London                                                         \n",
      "Barking & Dagenham  E09000002  50460.22660  51085.77983  51268.96956   \n",
      "Barnet              E09000003  93284.51832  93190.16963  92247.52435   \n",
      "Bexley              E09000004  64958.09036  64787.92069  64367.49344   \n",
      "Brent               E09000005  71306.56698  72022.26197  72015.76274   \n",
      "Bromley             E09000006  81671.47692  81657.55944  81449.31143   \n",
      "\n",
      "                    77101.20804  84409.14932  94900.51244  110128.0423  \\\n",
      "City of London                                                           \n",
      "Barking & Dagenham  53133.50526  53042.24852  53700.34831  52113.12157   \n",
      "Barnet              90762.87492  90258.00033  90107.23471  91441.24768   \n",
      "Bexley              64277.66881  63997.13588  64252.32335  63722.70055   \n",
      "Brent               72965.63094  73704.04743  74310.48167  74127.03788   \n",
      "Bromley             81124.41227  81542.61561  82382.83435  82898.52264   \n",
      "\n",
      "                    112329.4376  104473.1096  ...    975240    963094  \\\n",
      "City of London                                ...                       \n",
      "Barking & Dagenham  52232.19868  51471.61353  ...  355596.0  353429.0   \n",
      "Barnet              92361.31512  93273.12245  ...  592328.0  596085.0   \n",
      "Bexley              64432.60005  64509.54767  ...  409059.0  402365.0   \n",
      "Brent               73547.04110  73789.54287  ...  552767.0  551093.0   \n",
      "Bromley             82054.37156  81440.43008  ...  512263.0  508434.0   \n",
      "\n",
      "                      869039    930986    903718    958418    951649  \\\n",
      "City of London                                                         \n",
      "Barking & Dagenham  346193.0  345288.0  348254.0  349590.0  346099.0   \n",
      "Barnet              602336.0  596064.0  587132.0  575141.0  575829.0   \n",
      "Bexley              403398.0  399796.0  398544.0  391077.0  390880.0   \n",
      "Brent               534129.0  525561.0  523992.0  524452.0  531478.0   \n",
      "Bromley             500974.0  495896.0  497632.0  496393.0  497841.0   \n",
      "\n",
      "                      931176    861107    807475  \n",
      "City of London                                    \n",
      "Barking & Dagenham  343430.0  344171.0  345614.0  \n",
      "Barnet              583479.0  597591.0  584740.0  \n",
      "Bexley              396718.0  396278.0  396292.0  \n",
      "Brent               531425.0  557552.0  565929.0  \n",
      "Bromley             503888.0  509263.0  502753.0  \n",
      "\n",
      "[5 rows x 346 columns]\n"
     ]
    }
   ],
   "source": [
    "print(housing_df.head(5)) # the row of 'city of london' as header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d27ee388-72c1-4a8e-a87b-85b5f95206fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"Barking & Dagenham\" doesn't match format \"%Y%m%d\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## average price\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# set the index to datetime data\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m housing_df\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhousing_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# set the column and index name\u001b[39;00m\n\u001b[1;32m      6\u001b[0m housing_df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLondon_borough\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1121\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         result \u001b[38;5;241m=\u001b[39m _convert_and_box_cache(arg, cache_array, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1121\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(arg):\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1124\u001b[0m         \u001b[38;5;66;03m# error: Argument 1 to \"_maybe_cache\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[38;5;66;03m# \"Union[float, str, datetime, List[Any], Tuple[Any, ...], ExtensionArray,\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m         \u001b[38;5;66;03m# ndarray[Any, Any], Series]\"; expected \"Union[List[Any], Tuple[Any, ...],\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m         \u001b[38;5;66;03m# Union[Union[ExtensionArray, ndarray[Any, Any]], Index, Series], Series]\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:488\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64ns(\n\u001b[1;32m    491\u001b[0m     arg,\n\u001b[1;32m    492\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    496\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    497\u001b[0m )\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:519\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    509\u001b[0m     arg,\n\u001b[1;32m    510\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    514\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    515\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m    516\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     result, timezones \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m tz \u001b[38;5;129;01min\u001b[39;00m timezones):\n\u001b[1;32m    521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, utc, name)\n",
      "File \u001b[0;32mstrptime.pyx:534\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:355\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data \"Barking & Dagenham\" doesn't match format \"%Y%m%d\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "## average price\n",
    "\n",
    "# set the index to datetime data\n",
    "housing_df.index = pd.to_datetime(housing_df.index, format='%Y%m%d')\n",
    "# set the column and index name\n",
    "housing_df.columns.name = 'London_borough'\n",
    "housing_df.index.name = 'year'\n",
    "# check the index(year) type\n",
    "print(housing_df.index.dtype)\n",
    "# select the london borough data\n",
    "London_housing_df = housing_df.filter(regex='^E09', axis=1)\n",
    "# change the column and index location \n",
    "London_housing_df = London_housing_df.transpose()\n",
    "# check the data\n",
    "London_housing_df.head(3) \n",
    "\n",
    "# select the data of 2011 and 2021\n",
    "housing_ave_df = pd.DataFrame()\n",
    "housing_ave_df ['average_2011'] =London_housing_df.loc[:, ['2011-12-01']]\n",
    "housing_ave_df ['average_2021'] =London_housing_df.loc[:, ['2012-12-01']]\n",
    "housing_ave_df.head(10) \n",
    "\n",
    "# link the median data and average data\n",
    "total_housing_df = pd.merge(housing_ave_df,Housing_med_df, left_index=True, right_index=True)\n",
    "# calculate the change of housing price\n",
    "total_housing_df['Compare_2011'] = total_housing_df['median_2011']/total_housing_df['average_2011']\n",
    "total_housing_df['Compare_2021'] = total_housing_df['median_2021']/total_housing_df['average_2021']\n",
    "total_housing_df['houseprice%'] = (total_housing_df['Compare_2021']-total_housing_df['Compare_2011']) / total_housing_df['Compare_2011']\n",
    "\n",
    "print(total_housing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39330e09-bc4d-4a7a-9919-8fb890812af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 'houseprice%' to 'gtr'\n",
    "gtr = pd.merge(gtr, total_housing_df['houseprice%'], left_on='borough code', right_on='???', how='left')\n",
    "# Drop the redundant 'Area code' column in 'gtr'\n",
    "gtr = gtr.drop('???', axis=1)\n",
    "print(gtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa5cd5f-e023-4e97-9dea-47435c499548",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1.2.4 d: Deprivation Proportion Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06308f71-1a62-4321-b2fe-0f0dcee1d741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Area code dpr2011%   dpr2021%\n",
      "261  E09000007     37.9  47.523151\n",
      "262  E09000001       45  59.768010\n",
      "263  E09000012     31.5  44.952442\n",
      "264  E09000013     41.5  51.385949\n",
      "265  E09000014     35.7  43.316999\n",
      "266  E09000019     36.7  48.351227\n",
      "267  E09000020     43.6  52.589558\n",
      "268  E09000022     39.9  50.016334\n",
      "269  E09000023     38.4  47.211419\n",
      "270  E09000025       25  39.304111\n",
      "271  E09000028     36.2  48.546072\n",
      "272  E09000030     32.7  46.404898\n",
      "273  E09000032     50.4  58.362932\n",
      "274  E09000033     39.2  50.139746\n",
      "277  E09000002     28.2  37.591675\n",
      "278  E09000003     43.2  49.573264\n",
      "279  E09000004     41.5  48.518872\n",
      "280  E09000005     30.9  39.941996\n",
      "281  E09000006     48.5  54.642302\n",
      "282  E09000008       41  47.994717\n",
      "283  E09000009     37.4  46.034656\n",
      "284  E09000010     36.1  42.187397\n",
      "285  E09000011     37.2  48.243784\n",
      "286  E09000015     41.8  48.728275\n",
      "287  E09000016     39.7  47.298992\n",
      "288  E09000017     40.1  45.900319\n",
      "289  E09000018     37.3  44.100193\n",
      "290  E09000021     50.6  55.830006\n",
      "291  E09000024     46.5  53.906202\n",
      "292  E09000026     38.8  46.275780\n",
      "293  E09000027     57.6  61.038350\n",
      "294  E09000029     45.6  50.871909\n",
      "295  E09000031     34.3  45.262923\n"
     ]
    }
   ],
   "source": [
    "dpr2021_nodpr = dpr2021[dpr2021['Household deprivation (6 categories) Code'] == 1]\n",
    "dpr2021_all = dpr2021[(dpr2021['Household deprivation (6 categories) Code'] >= 1) & (dpr2021['Household deprivation (6 categories) Code'] <= 5)]\n",
    "sum = dpr2021_all.groupby('Upper tier local authorities Code')['Observation'].sum()\n",
    "\n",
    "ratios = (dpr2021_nodpr.groupby('Upper tier local authorities Code')['Observation'].sum() / sum) * 100\n",
    "\n",
    "# Create a new DataFrame by merging 'dpr2011' and 'ratios'\n",
    "result_df = pd.merge(dpr2011, ratios, left_on='Area code', right_index=True, how='left')\n",
    "result_df = result_df.rename(columns={'Observation': 'dpr2021%',\n",
    "                                      'Household is not deprived in any dimension': 'dpr2011%'})\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "248e5733-27c4-41f5-ba3f-2a477045142b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   borough borough code  2011moving%  2021moving%  popchurn%  \\\n",
      "0     Barking and Dagenham    E09000002    11.314102    11.096466  -0.217636   \n",
      "1                   Barnet    E09000003    13.528176    13.449671  -0.078505   \n",
      "2                   Bexley    E09000004     8.559739     9.228325   0.668586   \n",
      "3                    Brent    E09000005    14.025929    15.189397   1.163468   \n",
      "4                  Bromley    E09000006    10.936476    10.685033  -0.251443   \n",
      "5                   Camden    E09000007    19.379820    21.068651   1.688831   \n",
      "6           City of London    E09000001    27.085688    32.213164   5.127475   \n",
      "7                  Croydon    E09000008    11.519518    11.934819   0.415301   \n",
      "8                   Ealing    E09000009    13.772567    14.096957   0.324390   \n",
      "9                  Enfield    E09000010    12.009192    10.912710  -1.096482   \n",
      "10               Greenwich    E09000011    14.079714    13.880816  -0.198898   \n",
      "11                 Hackney    E09000012    15.340250    17.696536   2.356286   \n",
      "12  Hammersmith and Fulham    E09000013    19.660653    21.308668   1.648015   \n",
      "13                Haringey    E09000014    16.727549    15.956565  -0.770984   \n",
      "14                  Harrow    E09000015    11.357007    12.182632   0.825626   \n",
      "15                Havering    E09000016     8.166717     9.618064   1.451346   \n",
      "16              Hillingdon    E09000017    11.185262    11.658885   0.473623   \n",
      "17                Hounslow    E09000018    14.295874    13.560026  -0.735848   \n",
      "18               Islington    E09000019    18.308749    20.568013   2.259264   \n",
      "19  Kensington and Chelsea    E09000020    21.433206    21.731359   0.298153   \n",
      "20    Kingston upon Thames    E09000021    14.384456    13.944801  -0.439655   \n",
      "21                 Lambeth    E09000022    17.242787    18.535245   1.292458   \n",
      "22                Lewisham    E09000023    14.290862    14.331798   0.040935   \n",
      "23                  Merton    E09000024    14.170024    14.593653   0.423629   \n",
      "24                  Newham    E09000025    14.389341    16.223485   1.834143   \n",
      "25               Redbridge    E09000026    12.374547    12.375257   0.000710   \n",
      "26    Richmond upon Thames    E09000027    15.877061    14.257492  -1.619569   \n",
      "27               Southwark    E09000028    16.172823    17.516394   1.343571   \n",
      "28                  Sutton    E09000029    10.113656    10.656790   0.543134   \n",
      "29           Tower Hamlets    E09000030    20.403332    22.956356   2.553024   \n",
      "30          Waltham Forest    E09000031    13.050069    13.489598   0.439528   \n",
      "31              Wandsworth    E09000032    18.560413    20.299919   1.739505   \n",
      "32             Westminster    E09000033    22.667469    23.928932   1.261464   \n",
      "\n",
      "    w_ratio11  w_ratio21     ethgr% dpr2011%   dpr2021%  \n",
      "0    0.582020   0.449009  13.301165     28.2  37.591675  \n",
      "1    0.640884   0.577284   6.359992     43.2  49.573264  \n",
      "2    0.816123   0.718791   9.733167     41.5  48.518872  \n",
      "3    0.361679   0.346362   1.531746     30.9  39.941996  \n",
      "4    0.841295   0.764551   7.674403     48.5  54.642302  \n",
      "5    0.662110   0.595157   6.695261     37.9  47.523151  \n",
      "6    0.785898   0.693733   9.216578       45  59.768010  \n",
      "7    0.550284   0.483679   6.660471       41  47.994717  \n",
      "8    0.489049   0.431643   5.740571     37.4  46.034656  \n",
      "9    0.609013   0.520884   8.812918     36.1  42.187397  \n",
      "10   0.622933   0.556989   6.594426     37.2  48.243784  \n",
      "11   0.544699   0.531393   1.330553     31.5  44.952442  \n",
      "12   0.679506   0.631587   4.791823     41.5  51.385949  \n",
      "13   0.603991   0.569869   3.412213     35.7  43.316999  \n",
      "14   0.421700   0.364591   5.710932     41.8  48.728275  \n",
      "15   0.875889   0.752957  12.293200     39.7  47.298992  \n",
      "16   0.604838   0.481803  12.303506     40.1  45.900319  \n",
      "17   0.513166   0.440983   7.218234     37.3  44.100193  \n",
      "18   0.680907   0.622162   5.874553     36.7  48.351227  \n",
      "19   0.705318   0.637456   6.786188     43.6  52.589558  \n",
      "20   0.744246   0.683254   6.099240     50.6  55.830006  \n",
      "21   0.570234   0.550222   2.001225     39.9  50.016334  \n",
      "22   0.534563   0.514881   1.968241     38.4  47.211419  \n",
      "23   0.647945   0.602346   4.559873     46.5  53.906202  \n",
      "24   0.288177   0.307515  -1.933772       25  39.304111  \n",
      "25   0.424798   0.348010   7.678814     38.8  46.275780  \n",
      "26   0.859030   0.804555   5.447534     57.6  61.038350  \n",
      "27   0.541433   0.514302   2.713081     36.2  48.546072  \n",
      "28   0.784955   0.682826  10.212830     45.6  50.871909  \n",
      "29   0.451184   0.394018   5.716629     32.7  46.404898  \n",
      "30   0.520544   0.528050  -0.750621     34.3  45.262923  \n",
      "31   0.713539   0.678125   3.541433     50.4  58.362932  \n",
      "32   0.616483   0.551969   6.451415     39.2  50.139746  \n"
     ]
    }
   ],
   "source": [
    "# Merge 'result_df' with 'gtr'\n",
    "gtr = pd.merge(gtr, result_df[['Area code', 'dpr2011%', 'dpr2021%']], left_on='borough code', right_on='Area code', how='left')\n",
    "# Drop the redundant 'Area code' column in 'gtr'\n",
    "gtr = gtr.drop('Area code', axis=1)\n",
    "\n",
    "print(gtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7467b0b6-25ab-4069-a2c4-3ba95f1dfc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   borough borough code  2011moving%  2021moving%  popchurn%  \\\n",
      "0     Barking and Dagenham    E09000002    11.314102    11.096466  -0.217636   \n",
      "1                   Barnet    E09000003    13.528176    13.449671  -0.078505   \n",
      "2                   Bexley    E09000004     8.559739     9.228325   0.668586   \n",
      "3                    Brent    E09000005    14.025929    15.189397   1.163468   \n",
      "4                  Bromley    E09000006    10.936476    10.685033  -0.251443   \n",
      "5                   Camden    E09000007    19.379820    21.068651   1.688831   \n",
      "6           City of London    E09000001    27.085688    32.213164   5.127475   \n",
      "7                  Croydon    E09000008    11.519518    11.934819   0.415301   \n",
      "8                   Ealing    E09000009    13.772567    14.096957   0.324390   \n",
      "9                  Enfield    E09000010    12.009192    10.912710  -1.096482   \n",
      "10               Greenwich    E09000011    14.079714    13.880816  -0.198898   \n",
      "11                 Hackney    E09000012    15.340250    17.696536   2.356286   \n",
      "12  Hammersmith and Fulham    E09000013    19.660653    21.308668   1.648015   \n",
      "13                Haringey    E09000014    16.727549    15.956565  -0.770984   \n",
      "14                  Harrow    E09000015    11.357007    12.182632   0.825626   \n",
      "15                Havering    E09000016     8.166717     9.618064   1.451346   \n",
      "16              Hillingdon    E09000017    11.185262    11.658885   0.473623   \n",
      "17                Hounslow    E09000018    14.295874    13.560026  -0.735848   \n",
      "18               Islington    E09000019    18.308749    20.568013   2.259264   \n",
      "19  Kensington and Chelsea    E09000020    21.433206    21.731359   0.298153   \n",
      "20    Kingston upon Thames    E09000021    14.384456    13.944801  -0.439655   \n",
      "21                 Lambeth    E09000022    17.242787    18.535245   1.292458   \n",
      "22                Lewisham    E09000023    14.290862    14.331798   0.040935   \n",
      "23                  Merton    E09000024    14.170024    14.593653   0.423629   \n",
      "24                  Newham    E09000025    14.389341    16.223485   1.834143   \n",
      "25               Redbridge    E09000026    12.374547    12.375257   0.000710   \n",
      "26    Richmond upon Thames    E09000027    15.877061    14.257492  -1.619569   \n",
      "27               Southwark    E09000028    16.172823    17.516394   1.343571   \n",
      "28                  Sutton    E09000029    10.113656    10.656790   0.543134   \n",
      "29           Tower Hamlets    E09000030    20.403332    22.956356   2.553024   \n",
      "30          Waltham Forest    E09000031    13.050069    13.489598   0.439528   \n",
      "31              Wandsworth    E09000032    18.560413    20.299919   1.739505   \n",
      "32             Westminster    E09000033    22.667469    23.928932   1.261464   \n",
      "\n",
      "    w_ratio11  w_ratio21     ethgr% dpr2011%   dpr2021%       dpr%  \n",
      "0    0.582020   0.449009  13.301165     28.2  37.591675  -9.391675  \n",
      "1    0.640884   0.577284   6.359992     43.2  49.573264  -6.373264  \n",
      "2    0.816123   0.718791   9.733167     41.5  48.518872  -7.018872  \n",
      "3    0.361679   0.346362   1.531746     30.9  39.941996  -9.041996  \n",
      "4    0.841295   0.764551   7.674403     48.5  54.642302  -6.142302  \n",
      "5    0.662110   0.595157   6.695261     37.9  47.523151  -9.623151  \n",
      "6    0.785898   0.693733   9.216578       45  59.768010  -14.76801  \n",
      "7    0.550284   0.483679   6.660471       41  47.994717  -6.994717  \n",
      "8    0.489049   0.431643   5.740571     37.4  46.034656  -8.634656  \n",
      "9    0.609013   0.520884   8.812918     36.1  42.187397  -6.087397  \n",
      "10   0.622933   0.556989   6.594426     37.2  48.243784 -11.043784  \n",
      "11   0.544699   0.531393   1.330553     31.5  44.952442 -13.452442  \n",
      "12   0.679506   0.631587   4.791823     41.5  51.385949  -9.885949  \n",
      "13   0.603991   0.569869   3.412213     35.7  43.316999  -7.616999  \n",
      "14   0.421700   0.364591   5.710932     41.8  48.728275  -6.928275  \n",
      "15   0.875889   0.752957  12.293200     39.7  47.298992  -7.598992  \n",
      "16   0.604838   0.481803  12.303506     40.1  45.900319  -5.800319  \n",
      "17   0.513166   0.440983   7.218234     37.3  44.100193  -6.800193  \n",
      "18   0.680907   0.622162   5.874553     36.7  48.351227 -11.651227  \n",
      "19   0.705318   0.637456   6.786188     43.6  52.589558  -8.989558  \n",
      "20   0.744246   0.683254   6.099240     50.6  55.830006  -5.230006  \n",
      "21   0.570234   0.550222   2.001225     39.9  50.016334 -10.116334  \n",
      "22   0.534563   0.514881   1.968241     38.4  47.211419  -8.811419  \n",
      "23   0.647945   0.602346   4.559873     46.5  53.906202  -7.406202  \n",
      "24   0.288177   0.307515  -1.933772       25  39.304111 -14.304111  \n",
      "25   0.424798   0.348010   7.678814     38.8  46.275780   -7.47578  \n",
      "26   0.859030   0.804555   5.447534     57.6  61.038350   -3.43835  \n",
      "27   0.541433   0.514302   2.713081     36.2  48.546072 -12.346072  \n",
      "28   0.784955   0.682826  10.212830     45.6  50.871909  -5.271909  \n",
      "29   0.451184   0.394018   5.716629     32.7  46.404898 -13.704898  \n",
      "30   0.520544   0.528050  -0.750621     34.3  45.262923 -10.962923  \n",
      "31   0.713539   0.678125   3.541433     50.4  58.362932  -7.962932  \n",
      "32   0.616483   0.551969   6.451415     39.2  50.139746 -10.939746  \n"
     ]
    }
   ],
   "source": [
    "# add deprivation change to 'gtr'\n",
    "gtr['dpr%'] = gtr['dpr2011%'] - gtr['dpr2021%']\n",
    "print(gtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965dd34d-5177-47ba-a90b-2e1df6f47fff",
   "metadata": {},
   "source": [
    "#### 1.2.5  Gentrification Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2f9a8b-a303-4265-bf43-5ac6a8b83959",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtr['score'] = (1/2*gtr['popchurn%'] - 1/4*gtr['ethgr%'] \n",
    "                + 1/8*gtr['houseprice%'] -1/8*gtr['dpr%']) + 0.25\n",
    "print(gtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9af3225-bfd5-4c0c-8752-8f13c614e307",
   "metadata": {},
   "source": [
    "### 1.3 Airbnb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fca4ae2b-6ccd-407e-b1e4-c086af7ff086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Data/Boroughs.gpkg/Boroughs.gpkg locally!\n",
      "                   NAME   GSS_CODE   HECTARES  NONLD_AREA ONS_INNER  \\\n",
      "0  Kingston upon Thames  E09000021   3726.117       0.000         F   \n",
      "1               Croydon  E09000008   8649.441       0.000         F   \n",
      "2               Bromley  E09000006  15013.487       0.000         F   \n",
      "3              Hounslow  E09000018   5658.541      60.755         F   \n",
      "4                Ealing  E09000009   5554.428       0.000         F   \n",
      "5              Havering  E09000016  11445.735     210.763         F   \n",
      "6            Hillingdon  E09000017  11570.063       0.000         F   \n",
      "7                Harrow  E09000015   5046.330       0.000         F   \n",
      "8                 Brent  E09000005   4323.270       0.000         F   \n",
      "9                Barnet  E09000003   8674.837       0.000         F   \n",
      "\n",
      "                                            geometry  \n",
      "0  MULTIPOLYGON (((516401.600 160201.800, 516407....  \n",
      "1  MULTIPOLYGON (((535009.200 159504.700, 535005....  \n",
      "2  MULTIPOLYGON (((540373.600 157530.400, 540361....  \n",
      "3  MULTIPOLYGON (((521975.800 178100.000, 521967....  \n",
      "4  MULTIPOLYGON (((510253.500 182881.600, 510249....  \n",
      "5  MULTIPOLYGON (((549893.900 181459.800, 549894....  \n",
      "6  MULTIPOLYGON (((510599.800 191689.500, 510615....  \n",
      "7  MULTIPOLYGON (((510599.800 191689.500, 510660....  \n",
      "8  MULTIPOLYGON (((525201.000 182512.600, 525181....  \n",
      "9  MULTIPOLYGON (((524579.900 198355.200, 524594....  \n",
      "Found Data/listings.csv.gz locally!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '1,000.00'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://data.insideairbnb.com/united-kingdom/england/london/2022-12-10/data/listings.csv.gz\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m ls \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(cache_data(url, dest),compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m'\u001b[39m,usecols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbedrooms\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimum_nights\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 11\u001b[0m gls[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgls\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(ls\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py:6532\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6528\u001b[0m     results \u001b[38;5;241m=\u001b[39m [ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m   6530\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6531\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6532\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6533\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6534\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/internals/managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    412\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/internals/managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/internals/blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    614\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 616\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    620\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:238\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    235\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:183\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:134\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '1,000.00'"
     ]
    }
   ],
   "source": [
    "dest = 'Data/'\n",
    "\n",
    "# boroughs\n",
    "boros = gpd.read_file(cache_data('https://github.com/jreades/fsds/blob/master/data/src/Boroughs.gpkg?raw=true', dest+'Boroughs.gpkg') )\n",
    "boros.crs\n",
    "print(boros.head(10))\n",
    "\n",
    "# listings\n",
    "url = 'http://data.insideairbnb.com/united-kingdom/england/london/2022-12-10/data/listings.csv.gz'\n",
    "ls = pd.read_csv(cache_data(url, dest),compression='gzip',usecols=['id','latitude','longitude','price','bedrooms','minimum_nights'])\n",
    "gls['price'] = gls['price'].str.replace('$', '').astype(float)\n",
    "\n",
    "print(ls.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e893ae46-a86e-4d31-8481-de51096a5b09",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '79.00'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ls to Gegpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m gls \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(ls, \n\u001b[1;32m      3\u001b[0m       geometry\u001b[38;5;241m=\u001b[39mgpd\u001b[38;5;241m.\u001b[39mpoints_from_xy(ls\u001b[38;5;241m.\u001b[39mlongitude, ls\u001b[38;5;241m.\u001b[39mlatitude, crs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepsg:27700\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m----> 4\u001b[0m gls[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgls\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(gls\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py:6532\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6528\u001b[0m     results \u001b[38;5;241m=\u001b[39m [ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m   6530\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6531\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6532\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6533\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6534\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/internals/managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    412\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/internals/managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/internals/blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    614\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 616\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    620\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:238\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    235\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:183\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:134\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '79.00'"
     ]
    }
   ],
   "source": [
    "# ls to Gegpd\n",
    "gls = gpd.GeoDataFrame(ls, \n",
    "      geometry=gpd.points_from_xy(ls.longitude, ls.latitude, crs='epsg:27700'))\n",
    "gls['price'] = gls['price'].str.replace('$', '').astype(int)\n",
    "\n",
    "print(gls.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af1947cc-123b-477a-adf8-70a86b54ab1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   NAME   GSS_CODE   HECTARES  NONLD_AREA ONS_INNER  \\\n",
      "0  Kingston upon Thames  E09000021   3726.117       0.000         F   \n",
      "1               Croydon  E09000008   8649.441       0.000         F   \n",
      "2               Bromley  E09000006  15013.487       0.000         F   \n",
      "3              Hounslow  E09000018   5658.541      60.755         F   \n",
      "4                Ealing  E09000009   5554.428       0.000         F   \n",
      "5              Havering  E09000016  11445.735     210.763         F   \n",
      "6            Hillingdon  E09000017  11570.063       0.000         F   \n",
      "7                Harrow  E09000015   5046.330       0.000         F   \n",
      "8                 Brent  E09000005   4323.270       0.000         F   \n",
      "9                Barnet  E09000003   8674.837       0.000         F   \n",
      "\n",
      "                                            geometry  \n",
      "0  MULTIPOLYGON (((516401.600 160201.800, 516407....  \n",
      "1  MULTIPOLYGON (((535009.200 159504.700, 535005....  \n",
      "2  MULTIPOLYGON (((540373.600 157530.400, 540361....  \n",
      "3  MULTIPOLYGON (((521975.800 178100.000, 521967....  \n",
      "4  MULTIPOLYGON (((510253.500 182881.600, 510249....  \n",
      "5  MULTIPOLYGON (((549893.900 181459.800, 549894....  \n",
      "6  MULTIPOLYGON (((510599.800 191689.500, 510615....  \n",
      "7  MULTIPOLYGON (((510599.800 191689.500, 510660....  \n",
      "8  MULTIPOLYGON (((525201.000 182512.600, 525181....  \n",
      "9  MULTIPOLYGON (((524579.900 198355.200, 524594....  \n"
     ]
    }
   ],
   "source": [
    "# add gentrification score to borough dataframe\n",
    "merged_df = pd.merge(boros, gtr[['borough code', 'score']], left_on='GSS_CODE', right_on='borough code', how='left')\n",
    "merged_df = merged_df.drop('borough code', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360615f1-ec34-4968-b924-a191d91d4672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d861d50b-72c2-4db0-ad89-18a5738fed07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb3d7c3-8c70-474d-9056-02f8d1804f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9478af7-e5b2-4c30-83aa-cdf81d767147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "344abe29-adb7-410e-be2b-dad4ae25f5b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Don't mind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794758a0-712a-40e4-8150-c5f8615c91d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed3a92d-d04b-4315-9ba7-374455ec6ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data source\n",
    "# https://cycling.data.tfl.gov.uk/\n",
    "\n",
    "# files saved under Data/ActiveTravelCounts\n",
    "dir = 'Data/ActiveTravelCounts'\n",
    "# raw files\n",
    "loc_raw = '0-Count locations.csv'\n",
    "central_raw = '2022-Central.csv'\n",
    "inner_raw1 = '2022-Inner-Part1.csv'\n",
    "inner_raw2 = '2022-Inner-Part2.csv'\n",
    "outer_raw = '2022-Outer.csv'\n",
    "# saved file name\n",
    "location_fn = 'count_locations.geoparquet'\n",
    "travelcounts_fn = 'travel_counts.parquet'\n",
    "\n",
    "# geodataframe for points data will be saved as loc_gdf\n",
    "# dataframe for counts will be saved as counts_df\n",
    "\n",
    "# load the points data\n",
    "\n",
    "# check if gpkg file already exists\n",
    "# if not, convert the raw file into geoparquet after reading it in\n",
    "if not os.path.exists(os.path.join(dir, location_fn)):\n",
    "    print(\"Loading locations from csv and saving as geoparquet\")\n",
    "    loc_df = pd.read_csv(os.path.join(dir, loc_raw))\n",
    "    loc_gdf = gpd.GeoDataFrame(loc_df, geometry = gpd.points_from_xy(loc_df['Easting (UK Grid)'], loc_df['Northing (UK Grid)'], crs = 'EPSG:27700'))\n",
    "    # convert Functional area for monitoring into category\n",
    "    loc_gdf['Functional area for monitoring'] = loc_gdf['Functional area for monitoring'].astype('category')\n",
    "    loc_gdf.to_parquet(os.path.join(dir, location_fn))\n",
    "\n",
    "# if file already there, load from gpkg\n",
    "else:\n",
    "    print(\"Loading locations from processed geoparquet\")\n",
    "    loc_gdf = gpd.read_parquet(os.path.join(dir, location_fn))\n",
    "\n",
    "print(\"Location load complete. Use loc_gdf\")\n",
    "\n",
    "# load the travel counts data\n",
    "# check if file already exists\n",
    "# if not, load from csv and save the chunk before analysis\n",
    "\n",
    "if not os.path.exists(os.path.join(dir, travelcounts_fn)):\n",
    "    print(\"Loading counts from CSV and cleaning data\")\n",
    "\n",
    "    # load files\n",
    "    cen_df = pd.read_csv(os.path.join(dir, central_raw))\n",
    "    in1_df = pd.read_csv(os.path.join(dir, inner_raw1))\n",
    "    in2_df = pd.read_csv(os.path.join(dir, inner_raw2))\n",
    "    out_df = pd.read_csv(os.path.join(dir, outer_raw))\n",
    "\n",
    "    # add zone\n",
    "    cen_df.insert(2, 'Zone', 'Central')\n",
    "    in1_df.insert(2, 'Zone', 'Inner')\n",
    "    in2_df.insert(2, 'Zone', 'Inner')\n",
    "    out_df.insert(2, 'Zone', 'Outer')\n",
    "\n",
    "    # join data frames\n",
    "    counts_df = pd.concat([cen_df, in1_df, in2_df, out_df])\n",
    "\n",
    "    # clean data\n",
    "    # insert datetime column in datetime format\n",
    "    counts_df.insert(3, 'datetime', pd.to_datetime(counts_df['Date'] + ' ' + counts_df['Time'], dayfirst = True))\n",
    "    \n",
    "    # turn into categorical data\n",
    "    categorical = ['Zone', 'Weather', 'Day', 'Round', 'Dir', 'Path', 'Mode']\n",
    "    \n",
    "    for c in categorical:\n",
    "        counts_df[c] = counts_df[c].astype('category')\n",
    "\n",
    "    # save parquet file\n",
    "    counts_df.to_parquet(os.path.join(dir, travelcounts_fn))\n",
    "\n",
    "# if file already there, load from parquet\n",
    "else:\n",
    "    print(\"Loading counts from processed parquet\")\n",
    "    counts_df = pd.read_parquet(os.path.join(dir, travelcounts_fn))\n",
    "\n",
    "print(\"Counts load complete. Use counts_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acce81c-8a5a-4a18-a101-436dfcf365f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Looking at the `loc_gdf` Geodataframe\n",
    "\n",
    "Check to confirm file loading is done correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0981240d-d0c2-4dff-8eb4-969286ce06ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 2297 entries, 0 to 2296\n",
      "Data columns (total 13 columns):\n",
      " #   Column                             Non-Null Count  Dtype   \n",
      "---  ------                             --------------  -----   \n",
      " 0   Site ID                            2297 non-null   object  \n",
      " 1   Which folder?                      2297 non-null   object  \n",
      " 2   Shared sites                       2297 non-null   object  \n",
      " 3   Location description               2297 non-null   object  \n",
      " 4   Borough                            2297 non-null   object  \n",
      " 5   Functional area for monitoring     2297 non-null   category\n",
      " 6   Road type                          2297 non-null   object  \n",
      " 7   Is it on the strategic CIO panel?  2297 non-null   int64   \n",
      " 8   Easting (UK Grid)                  2297 non-null   float64 \n",
      " 9   Northing (UK Grid)                 2297 non-null   float64 \n",
      " 10  Latitude                           2297 non-null   float64 \n",
      " 11  Longitude                          2297 non-null   float64 \n",
      " 12  geometry                           2297 non-null   geometry\n",
      "dtypes: category(1), float64(4), geometry(1), int64(1), object(6)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "loc_gdf.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
