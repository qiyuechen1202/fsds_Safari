{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1efb9da3-ff66-48c4-9760-b55425017d70",
   "metadata": {},
   "source": [
    "# FSDS Group Assessment (Group Safari)\n",
    "\n",
    "## 1. Data Collection and Cleaning\n",
    "We will use 2 different datasets:\n",
    "1. Airbnb data of London (10 Dec, 2022) downloading from [InsideAirbnb](http://insideairbnb.com/get-the-data)  \n",
    "2. 2011 and 2021 Census data including:\n",
    "* .csv\n",
    "* .csv\n",
    "* .xls\n",
    "* .xlsx\n",
    "* ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900b1c81-c4e8-44ec-bd43-9ecb7886b2bc",
   "metadata": {},
   "source": [
    "### 1.1 Input data and create dataframe and geodataframe\n",
    "\n",
    "Note that all data in the Data subdirectory is ignored in the `.gitignore` file. <span style=\"color:red\">(***We may need to change the setting of our repo later.***)</span>\n",
    "\n",
    "The file names that are created through this script is as follows.\n",
    "\n",
    "|Data|File name|df/gdf name|\n",
    "|:---|:---|:---|\n",
    "|Points|`***`|`***`|\n",
    "|Trips|`***`|`***`|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d77d5c-c664-4d78-a926-4b4d32dc68c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<jemalloc>: MADV_DONTNEED does not work (memset will be used instead)\n",
      "<jemalloc>: (This is the expected behaviour if you are running under QEMU)\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "from requests import get\n",
    "from urllib.parse import urlparse\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbef2c0-2843-4212-b6be-3692565aa8b9",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">For now, I am using local files, so the next coding cell won't be helpful. But I'll adjust it later to download directly using url.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3951fa7b-2975-4e9f-8df7-6170dfc70b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from remote location\n",
    "def cache_data(src:str, dest:str) -> str:\n",
    "    \"\"\"Downloads and caches a remote file locally.\n",
    "    \n",
    "    The function sits between the 'read' step of a pandas or geopandas\n",
    "    data frame and downloading the file from a remote location. The idea\n",
    "    is that it will save it locally so that you don't need to remember to\n",
    "    do so yourself. Subsequent re-reads of the file will return instantly\n",
    "    rather than downloading the entire file for a second or n-th itme.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    src : str\n",
    "        The remote *source* for the file, any valid URL should work.\n",
    "    dest : str\n",
    "        The *destination* location to save the downloaded file.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A string representing the local location of the file.\n",
    "    \"\"\"\n",
    "    url = urlparse(src)\n",
    "    fn  = os.path.split(url.path)[-1]\n",
    "    dfn = os.path.join(dest,fn)\n",
    "    \n",
    "    if not os.path.isfile(dfn):\n",
    "        print(f\"{dfn} not found, downloading!\")\n",
    "        path = os.path.split(dest)\n",
    "        \n",
    "        if len(path) >= 1 and path[0] != '':\n",
    "            os.makedirs(os.path.join(*path), exist_ok=True)\n",
    "            \n",
    "        with open(dfn, \"wb\") as file:\n",
    "            response = get(src)\n",
    "            file.write(response.content)  \n",
    "        print(\"\\tDone downloading...\")\n",
    "    else:\n",
    "        print(f\"Found {dfn} locally!\")\n",
    "        \n",
    "    return dfn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed83e647-0164-42e2-a536-44db194e955e",
   "metadata": {},
   "source": [
    "Please save data files under directory: ***fsds/group/Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9336107a-6380-4e54-8fbf-7a6a1bd8a712",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/jovyan/work/Documents/casa/fsds/group')\n",
    "padir = 'Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5815cc2a-9269-4508-bfb8-11e535210892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files used for gentrification score\n",
    "\n",
    "## Population Churn\n",
    "popch2011 = pd.read_csv(padir+'popchurn 11.csv', skiprows=7, header=0, skip_blank_lines=True, usecols=[\n",
    "    'mnemonic',\n",
    "    'Whole household lived at same address one year ago', \n",
    "    'Wholly moving household: Total']).dropna(how='all')\n",
    "\n",
    "popch2021_in_raw = pd.read_csv(padir+'MIG009EW_LTLA_IN.csv',usecols=[\n",
    "    'Lower tier local authorities code',\n",
    "    'Household migration LTLA (inflow) (7 categories) code',\n",
    "    'Count'])\n",
    "popch2021_out_raw = pd.read_csv(padir+'MIG009EW_LTLA_OUT.csv',usecols=[\n",
    "    'Migrant LTLA one year ago code', \n",
    "    'Household migration LTLA (outflow) (3 categories) code',\n",
    "    'Count'])\n",
    "popch2021_in = popch2021_in_raw.loc[popch2021_in_raw['Lower tier local authorities code'].astype(str).str.contains(r'^E090000[0-2][0-9]$|^E090003[0-3]$', regex=True)]\n",
    "popch2021_out = popch2021_out_raw.loc[popch2021_out_raw['Migrant LTLA one year ago code'].astype(str).str.contains(r'^E090000[0-2][0-9]$|^E090003[0-3]$', regex=True)]\n",
    "\n",
    "## Ethnic Group\n",
    "eg2011 = pd.read_csv(padir+'ethnic group 2011.csv', skiprows=7, header=0, skip_blank_lines=True, usecols=[\n",
    "    'mnemonic','All categories: Ethnic group','White'])\n",
    "eg2021 = pd.read_csv(padir+'ethnic group 2021.csv', skiprows=6, header=0, skip_blank_lines=True, usecols=[\n",
    "    'mnemonic','Total: All usual residents','White'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b114084b-b276-413d-b464-30106c4d800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Housing Price\n",
    "price_med_raw = pd.read_excel(padir+'house price _median by MSOA.xls',sheet_name='1a', skiprows=4,header=0,\n",
    "                              usecols=['Local authority code','Year ending Dec 2001','Year ending Dec 2021'])\n",
    "price_med = price_med_raw.loc[price_med_raw['Local authority code'].astype(str).str.contains(r'^E090000[0-2][0-9]$|^E090003[0-3]$', regex=True)]\n",
    "price_aver_raw = pd.read_excel(padir+'house price index_aver.xlsx', sheet_name = 'Average price',skiprows=0, header=0,userows=['Dec-11','Dec-21']).transpose().rename_axis('Area code')\n",
    "price_aver = price_aver_raw.loc[price_aver_raw['Area code'].astype(str).str.contains(r'^E090000[0-2][0-9]$|^E090003[0-3]$', regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b8b763-eca2-4ff5-8990-51ec9eb92b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eaa4bf-6e1c-4de1-8c57-4b666dcbfeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e168a9-27f0-45f5-a55f-a10850b5a980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794758a0-712a-40e4-8150-c5f8615c91d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a02d6029-219a-482b-99f3-c4b95f108a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mnemonic</th>\n",
       "      <th>Total: All usual residents</th>\n",
       "      <th>White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>E09000018</td>\n",
       "      <td>288181.0</td>\n",
       "      <td>127083.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>by small amounts. Small counts at the lowest g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>published&lt;FIELD=ENDLINE&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             mnemonic  \\\n",
       "17                                          E09000018   \n",
       "37  by small amounts. Small counts at the lowest g...   \n",
       "34                           published<FIELD=ENDLINE>   \n",
       "\n",
       "    Total: All usual residents     White  \n",
       "17                    288181.0  127083.0  \n",
       "37                         NaN       NaN  \n",
       "34                         NaN       NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "# Display the filtered DataFrame\n",
    "popch2011.sample(3,random_state=7)\n",
    "popch2021_in.sample(3,random_state=7)\n",
    "popch2021_out.sample(3,random_state=7)\n",
    "eg2011.sample(3,random_state=7)\n",
    "eg2021.sample(3,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ed3a92d-d04b-4315-9ba7-374455ec6ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading locations from processed geoparquet\n",
      "Location load complete. Use loc_gdf\n",
      "Loading counts from processed parquet\n",
      "Counts load complete. Use counts_df\n"
     ]
    }
   ],
   "source": [
    "# data source\n",
    "# https://cycling.data.tfl.gov.uk/\n",
    "\n",
    "# files saved under Data/ActiveTravelCounts\n",
    "dir = 'Data/ActiveTravelCounts'\n",
    "# raw files\n",
    "loc_raw = '0-Count locations.csv'\n",
    "central_raw = '2022-Central.csv'\n",
    "inner_raw1 = '2022-Inner-Part1.csv'\n",
    "inner_raw2 = '2022-Inner-Part2.csv'\n",
    "outer_raw = '2022-Outer.csv'\n",
    "# saved file name\n",
    "location_fn = 'count_locations.geoparquet'\n",
    "travelcounts_fn = 'travel_counts.parquet'\n",
    "\n",
    "# geodataframe for points data will be saved as loc_gdf\n",
    "# dataframe for counts will be saved as counts_df\n",
    "\n",
    "# load the points data\n",
    "\n",
    "# check if gpkg file already exists\n",
    "# if not, convert the raw file into geoparquet after reading it in\n",
    "if not os.path.exists(os.path.join(dir, location_fn)):\n",
    "    print(\"Loading locations from csv and saving as geoparquet\")\n",
    "    loc_df = pd.read_csv(os.path.join(dir, loc_raw))\n",
    "    loc_gdf = gpd.GeoDataFrame(loc_df, geometry = gpd.points_from_xy(loc_df['Easting (UK Grid)'], loc_df['Northing (UK Grid)'], crs = 'EPSG:27700'))\n",
    "    # convert Functional area for monitoring into category\n",
    "    loc_gdf['Functional area for monitoring'] = loc_gdf['Functional area for monitoring'].astype('category')\n",
    "    loc_gdf.to_parquet(os.path.join(dir, location_fn))\n",
    "\n",
    "# if file already there, load from gpkg\n",
    "else:\n",
    "    print(\"Loading locations from processed geoparquet\")\n",
    "    loc_gdf = gpd.read_parquet(os.path.join(dir, location_fn))\n",
    "\n",
    "print(\"Location load complete. Use loc_gdf\")\n",
    "\n",
    "# load the travel counts data\n",
    "# check if file already exists\n",
    "# if not, load from csv and save the chunk before analysis\n",
    "\n",
    "if not os.path.exists(os.path.join(dir, travelcounts_fn)):\n",
    "    print(\"Loading counts from CSV and cleaning data\")\n",
    "\n",
    "    # load files\n",
    "    cen_df = pd.read_csv(os.path.join(dir, central_raw))\n",
    "    in1_df = pd.read_csv(os.path.join(dir, inner_raw1))\n",
    "    in2_df = pd.read_csv(os.path.join(dir, inner_raw2))\n",
    "    out_df = pd.read_csv(os.path.join(dir, outer_raw))\n",
    "\n",
    "    # add zone\n",
    "    cen_df.insert(2, 'Zone', 'Central')\n",
    "    in1_df.insert(2, 'Zone', 'Inner')\n",
    "    in2_df.insert(2, 'Zone', 'Inner')\n",
    "    out_df.insert(2, 'Zone', 'Outer')\n",
    "\n",
    "    # join data frames\n",
    "    counts_df = pd.concat([cen_df, in1_df, in2_df, out_df])\n",
    "\n",
    "    # clean data\n",
    "    # insert datetime column in datetime format\n",
    "    counts_df.insert(3, 'datetime', pd.to_datetime(counts_df['Date'] + ' ' + counts_df['Time'], dayfirst = True))\n",
    "    \n",
    "    # turn into categorical data\n",
    "    categorical = ['Zone', 'Weather', 'Day', 'Round', 'Dir', 'Path', 'Mode']\n",
    "    \n",
    "    for c in categorical:\n",
    "        counts_df[c] = counts_df[c].astype('category')\n",
    "\n",
    "    # save parquet file\n",
    "    counts_df.to_parquet(os.path.join(dir, travelcounts_fn))\n",
    "\n",
    "# if file already there, load from parquet\n",
    "else:\n",
    "    print(\"Loading counts from processed parquet\")\n",
    "    counts_df = pd.read_parquet(os.path.join(dir, travelcounts_fn))\n",
    "\n",
    "print(\"Counts load complete. Use counts_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acce81c-8a5a-4a18-a101-436dfcf365f7",
   "metadata": {},
   "source": [
    "### Looking at the `loc_gdf` Geodataframe\n",
    "\n",
    "Check to confirm file loading is done correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0981240d-d0c2-4dff-8eb4-969286ce06ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 2297 entries, 0 to 2296\n",
      "Data columns (total 13 columns):\n",
      " #   Column                             Non-Null Count  Dtype   \n",
      "---  ------                             --------------  -----   \n",
      " 0   Site ID                            2297 non-null   object  \n",
      " 1   Which folder?                      2297 non-null   object  \n",
      " 2   Shared sites                       2297 non-null   object  \n",
      " 3   Location description               2297 non-null   object  \n",
      " 4   Borough                            2297 non-null   object  \n",
      " 5   Functional area for monitoring     2297 non-null   category\n",
      " 6   Road type                          2297 non-null   object  \n",
      " 7   Is it on the strategic CIO panel?  2297 non-null   int64   \n",
      " 8   Easting (UK Grid)                  2297 non-null   float64 \n",
      " 9   Northing (UK Grid)                 2297 non-null   float64 \n",
      " 10  Latitude                           2297 non-null   float64 \n",
      " 11  Longitude                          2297 non-null   float64 \n",
      " 12  geometry                           2297 non-null   geometry\n",
      "dtypes: category(1), float64(4), geometry(1), int64(1), object(6)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "loc_gdf.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
